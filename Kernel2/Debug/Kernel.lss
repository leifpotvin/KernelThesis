
Kernel.elf:     file format elf32-avr

Sections:
Idx Name          Size      VMA       LMA       File off  Algn
  0 .data         00000000  00800200  00800200  000006b2  2**0
                  CONTENTS, ALLOC, LOAD, DATA
  1 .text         0000063e  00000000  00000000  00000074  2**1
                  CONTENTS, ALLOC, LOAD, READONLY, CODE
  2 .bss          00000458  00800200  00800200  000006b2  2**0
                  ALLOC
  3 .comment      00000030  00000000  00000000  000006b2  2**0
                  CONTENTS, READONLY
  4 .note.gnu.avr.deviceinfo 00000040  00000000  00000000  000006e4  2**2
                  CONTENTS, READONLY
  5 .debug_aranges 00000100  00000000  00000000  00000724  2**0
                  CONTENTS, READONLY, DEBUGGING
  6 .debug_info   00001c44  00000000  00000000  00000824  2**0
                  CONTENTS, READONLY, DEBUGGING
  7 .debug_abbrev 0000116b  00000000  00000000  00002468  2**0
                  CONTENTS, READONLY, DEBUGGING
  8 .debug_line   00000a11  00000000  00000000  000035d3  2**0
                  CONTENTS, READONLY, DEBUGGING
  9 .debug_frame  00000208  00000000  00000000  00003fe4  2**2
                  CONTENTS, READONLY, DEBUGGING
 10 .debug_str    0000083c  00000000  00000000  000041ec  2**0
                  CONTENTS, READONLY, DEBUGGING
 11 .debug_loc    00000456  00000000  00000000  00004a28  2**0
                  CONTENTS, READONLY, DEBUGGING
 12 .debug_ranges 000000d8  00000000  00000000  00004e7e  2**0
                  CONTENTS, READONLY, DEBUGGING

Disassembly of section .text:

00000000 <__vectors>:
   0:	71 c0       	rjmp	.+226    	; 0xe4 <__ctors_end>
   2:	00 00       	nop
   4:	81 c0       	rjmp	.+258    	; 0x108 <__bad_interrupt>
   6:	00 00       	nop
   8:	7f c0       	rjmp	.+254    	; 0x108 <__bad_interrupt>
   a:	00 00       	nop
   c:	7d c0       	rjmp	.+250    	; 0x108 <__bad_interrupt>
   e:	00 00       	nop
  10:	7b c0       	rjmp	.+246    	; 0x108 <__bad_interrupt>
  12:	00 00       	nop
  14:	79 c0       	rjmp	.+242    	; 0x108 <__bad_interrupt>
  16:	00 00       	nop
  18:	77 c0       	rjmp	.+238    	; 0x108 <__bad_interrupt>
  1a:	00 00       	nop
  1c:	75 c0       	rjmp	.+234    	; 0x108 <__bad_interrupt>
  1e:	00 00       	nop
  20:	73 c0       	rjmp	.+230    	; 0x108 <__bad_interrupt>
  22:	00 00       	nop
  24:	71 c0       	rjmp	.+226    	; 0x108 <__bad_interrupt>
  26:	00 00       	nop
  28:	6f c0       	rjmp	.+222    	; 0x108 <__bad_interrupt>
  2a:	00 00       	nop
  2c:	6d c0       	rjmp	.+218    	; 0x108 <__bad_interrupt>
  2e:	00 00       	nop
  30:	6b c0       	rjmp	.+214    	; 0x108 <__bad_interrupt>
  32:	00 00       	nop
  34:	ea c1       	rjmp	.+980    	; 0x40a <__vector_13>
  36:	00 00       	nop
  38:	3a c2       	rjmp	.+1140   	; 0x4ae <__vector_14>
  3a:	00 00       	nop
  3c:	65 c0       	rjmp	.+202    	; 0x108 <__bad_interrupt>
  3e:	00 00       	nop
  40:	63 c0       	rjmp	.+198    	; 0x108 <__bad_interrupt>
  42:	00 00       	nop
  44:	61 c0       	rjmp	.+194    	; 0x108 <__bad_interrupt>
  46:	00 00       	nop
  48:	5f c0       	rjmp	.+190    	; 0x108 <__bad_interrupt>
  4a:	00 00       	nop
  4c:	5d c0       	rjmp	.+186    	; 0x108 <__bad_interrupt>
  4e:	00 00       	nop
  50:	5b c0       	rjmp	.+182    	; 0x108 <__bad_interrupt>
  52:	00 00       	nop
  54:	59 c0       	rjmp	.+178    	; 0x108 <__bad_interrupt>
  56:	00 00       	nop
  58:	57 c0       	rjmp	.+174    	; 0x108 <__bad_interrupt>
  5a:	00 00       	nop
  5c:	55 c0       	rjmp	.+170    	; 0x108 <__bad_interrupt>
  5e:	00 00       	nop
  60:	53 c0       	rjmp	.+166    	; 0x108 <__bad_interrupt>
  62:	00 00       	nop
  64:	51 c0       	rjmp	.+162    	; 0x108 <__bad_interrupt>
  66:	00 00       	nop
  68:	4f c0       	rjmp	.+158    	; 0x108 <__bad_interrupt>
  6a:	00 00       	nop
  6c:	4d c0       	rjmp	.+154    	; 0x108 <__bad_interrupt>
  6e:	00 00       	nop
  70:	4b c0       	rjmp	.+150    	; 0x108 <__bad_interrupt>
  72:	00 00       	nop
  74:	49 c0       	rjmp	.+146    	; 0x108 <__bad_interrupt>
  76:	00 00       	nop
  78:	47 c0       	rjmp	.+142    	; 0x108 <__bad_interrupt>
  7a:	00 00       	nop
  7c:	45 c0       	rjmp	.+138    	; 0x108 <__bad_interrupt>
  7e:	00 00       	nop
  80:	43 c0       	rjmp	.+134    	; 0x108 <__bad_interrupt>
  82:	00 00       	nop
  84:	41 c0       	rjmp	.+130    	; 0x108 <__bad_interrupt>
  86:	00 00       	nop
  88:	3f c0       	rjmp	.+126    	; 0x108 <__bad_interrupt>
  8a:	00 00       	nop
  8c:	3d c0       	rjmp	.+122    	; 0x108 <__bad_interrupt>
  8e:	00 00       	nop
  90:	3b c0       	rjmp	.+118    	; 0x108 <__bad_interrupt>
  92:	00 00       	nop
  94:	39 c0       	rjmp	.+114    	; 0x108 <__bad_interrupt>
  96:	00 00       	nop
  98:	37 c0       	rjmp	.+110    	; 0x108 <__bad_interrupt>
  9a:	00 00       	nop
  9c:	35 c0       	rjmp	.+106    	; 0x108 <__bad_interrupt>
  9e:	00 00       	nop
  a0:	33 c0       	rjmp	.+102    	; 0x108 <__bad_interrupt>
  a2:	00 00       	nop
  a4:	31 c0       	rjmp	.+98     	; 0x108 <__bad_interrupt>
  a6:	00 00       	nop
  a8:	2f c0       	rjmp	.+94     	; 0x108 <__bad_interrupt>
  aa:	00 00       	nop
  ac:	2d c0       	rjmp	.+90     	; 0x108 <__bad_interrupt>
  ae:	00 00       	nop
  b0:	2b c0       	rjmp	.+86     	; 0x108 <__bad_interrupt>
  b2:	00 00       	nop
  b4:	29 c0       	rjmp	.+82     	; 0x108 <__bad_interrupt>
  b6:	00 00       	nop
  b8:	27 c0       	rjmp	.+78     	; 0x108 <__bad_interrupt>
  ba:	00 00       	nop
  bc:	25 c0       	rjmp	.+74     	; 0x108 <__bad_interrupt>
  be:	00 00       	nop
  c0:	23 c0       	rjmp	.+70     	; 0x108 <__bad_interrupt>
  c2:	00 00       	nop
  c4:	21 c0       	rjmp	.+66     	; 0x108 <__bad_interrupt>
  c6:	00 00       	nop
  c8:	1f c0       	rjmp	.+62     	; 0x108 <__bad_interrupt>
  ca:	00 00       	nop
  cc:	1d c0       	rjmp	.+58     	; 0x108 <__bad_interrupt>
  ce:	00 00       	nop
  d0:	1b c0       	rjmp	.+54     	; 0x108 <__bad_interrupt>
  d2:	00 00       	nop
  d4:	19 c0       	rjmp	.+50     	; 0x108 <__bad_interrupt>
  d6:	00 00       	nop
  d8:	17 c0       	rjmp	.+46     	; 0x108 <__bad_interrupt>
  da:	00 00       	nop
  dc:	15 c0       	rjmp	.+42     	; 0x108 <__bad_interrupt>
  de:	00 00       	nop
  e0:	13 c0       	rjmp	.+38     	; 0x108 <__bad_interrupt>
	...

000000e4 <__ctors_end>:
  e4:	11 24       	eor	r1, r1
  e6:	1f be       	out	0x3f, r1	; 63
  e8:	cf ef       	ldi	r28, 0xFF	; 255
  ea:	d1 e2       	ldi	r29, 0x21	; 33
  ec:	de bf       	out	0x3e, r29	; 62
  ee:	cd bf       	out	0x3d, r28	; 61
  f0:	00 e0       	ldi	r16, 0x00	; 0
  f2:	0c bf       	out	0x3c, r16	; 60

000000f4 <__do_clear_bss>:
  f4:	26 e0       	ldi	r18, 0x06	; 6
  f6:	a0 e0       	ldi	r26, 0x00	; 0
  f8:	b2 e0       	ldi	r27, 0x02	; 2
  fa:	01 c0       	rjmp	.+2      	; 0xfe <.do_clear_bss_start>

000000fc <.do_clear_bss_loop>:
  fc:	1d 92       	st	X+, r1

000000fe <.do_clear_bss_start>:
  fe:	a8 35       	cpi	r26, 0x58	; 88
 100:	b2 07       	cpc	r27, r18
 102:	e1 f7       	brne	.-8      	; 0xfc <.do_clear_bss_loop>
 104:	91 d2       	rcall	.+1314   	; 0x628 <main>
 106:	99 c2       	rjmp	.+1330   	; 0x63a <_exit>

00000108 <__bad_interrupt>:
 108:	7b cf       	rjmp	.-266    	; 0x0 <__vectors>

0000010a <stack_overflow>:
 *
 *	Current version indicates the error externally and never returns.
 */
void stack_overflow()
{
	DDRB |= 0x80;
 10a:	27 9a       	sbi	0x04, 7	; 4
	while (1)
	{
		PORTB ^= 0x80;
 10c:	85 b1       	in	r24, 0x05	; 5
 10e:	80 58       	subi	r24, 0x80	; 128
 110:	85 b9       	out	0x05, r24	; 5
	#else
		//round up by default
		__ticks_dc = (uint32_t)(ceil(fabs(__tmp)));
	#endif

	__builtin_avr_delay_cycles(__ticks_dc);
 112:	2f ef       	ldi	r18, 0xFF	; 255
 114:	84 e3       	ldi	r24, 0x34	; 52
 116:	9c e0       	ldi	r25, 0x0C	; 12
 118:	21 50       	subi	r18, 0x01	; 1
 11a:	80 40       	sbci	r24, 0x00	; 0
 11c:	90 40       	sbci	r25, 0x00	; 0
 11e:	e1 f7       	brne	.-8      	; 0x118 <stack_overflow+0xe>
 120:	00 c0       	rjmp	.+0      	; 0x122 <stack_overflow+0x18>
 122:	00 00       	nop
 124:	f3 cf       	rjmp	.-26     	; 0x10c <stack_overflow+0x2>

00000126 <uninitialized_thread_error>:
 *	to schedule a thread that has not been initialized.
 *	Current version indicates the error externally and never returns.
 */
void uninitialized_thread_error()
{
	DDRB |= 0x80;
 126:	27 9a       	sbi	0x04, 7	; 4
	while (1)
	{
		PORTB ^= 0x80;
 128:	85 b1       	in	r24, 0x05	; 5
 12a:	80 58       	subi	r24, 0x80	; 128
 12c:	85 b9       	out	0x05, r24	; 5
 12e:	2f ef       	ldi	r18, 0xFF	; 255
 130:	83 ed       	ldi	r24, 0xD3	; 211
 132:	90 e3       	ldi	r25, 0x30	; 48
 134:	21 50       	subi	r18, 0x01	; 1
 136:	80 40       	sbci	r24, 0x00	; 0
 138:	90 40       	sbci	r25, 0x00	; 0
 13a:	e1 f7       	brne	.-8      	; 0x134 <uninitialized_thread_error+0xe>
 13c:	00 c0       	rjmp	.+0      	; 0x13e <uninitialized_thread_error+0x18>
 13e:	00 00       	nop
 140:	f3 cf       	rjmp	.-26     	; 0x128 <uninitialized_thread_error+0x2>

00000142 <push_pthread>:
 *	func:	the function pointer to be pushed
 */
void push_pthread(uint8_t tid, PTHREAD func)
{
	// push low order byte
	*(kernel_data.thread_ctrl_tbl[tid].stack_ptr--) = 
 142:	28 e0       	ldi	r18, 0x08	; 8
 144:	82 9f       	mul	r24, r18
 146:	c0 01       	movw	r24, r0
 148:	11 24       	eor	r1, r1
 14a:	fc 01       	movw	r30, r24
 14c:	e0 50       	subi	r30, 0x00	; 0
 14e:	fa 4f       	sbci	r31, 0xFA	; 250
 150:	a0 81       	ld	r26, Z
 152:	b1 81       	ldd	r27, Z+1	; 0x01
 154:	cd 01       	movw	r24, r26
 156:	01 97       	sbiw	r24, 0x01	; 1
 158:	91 83       	std	Z+1, r25	; 0x01
 15a:	80 83       	st	Z, r24
 15c:	6c 93       	st	X, r22
		(uint8_t) ((((uint16_t) func) & 0x00ff) >> 0);
	// push middle order byte
	*(kernel_data.thread_ctrl_tbl[tid].stack_ptr--) = 
 15e:	a0 81       	ld	r26, Z
 160:	b1 81       	ldd	r27, Z+1	; 0x01
 162:	cd 01       	movw	r24, r26
 164:	01 97       	sbiw	r24, 0x01	; 1
 166:	91 83       	std	Z+1, r25	; 0x01
 168:	80 83       	st	Z, r24
 16a:	7c 93       	st	X, r23
	// push high order byte
	// because the ATmega2560 has a 17 bit address space for program memory 
	// and gcc uses 16 bit address space, the high order byte is always zero 
	// for a function pointer and trampoline tables are used for functions 
	// in high parts of program memory
	*(kernel_data.thread_ctrl_tbl[tid].stack_ptr--) = (uint8_t) (0x00);
 16c:	a0 81       	ld	r26, Z
 16e:	b1 81       	ldd	r27, Z+1	; 0x01
 170:	cd 01       	movw	r24, r26
 172:	01 97       	sbiw	r24, 0x01	; 1
 174:	91 83       	std	Z+1, r25	; 0x01
 176:	80 83       	st	Z, r24
 178:	1c 92       	st	X, r1
 17a:	08 95       	ret

0000017c <new>:
 *					in program memory must make use of a trampoline table
 *	enabled:		boolean value. True if the thread should be enabled 
 *					when this function exits
 */
void new(uint8_t tid, PTHREAD entry_point, bool enabled)
{
 17c:	ff 92       	push	r15
 17e:	0f 93       	push	r16
 180:	1f 93       	push	r17
 182:	cf 93       	push	r28
 184:	df 93       	push	r29
 186:	c8 2f       	mov	r28, r24
 188:	f4 2e       	mov	r15, r20
	ATOMIC_BLOCK(ATOMIC_RESTORESTATE)
 18a:	df b7       	in	r29, 0x3f	; 63
    return 1;
}

static __inline__ uint8_t __iCliRetVal(void)
{
    cli();
 18c:	f8 94       	cli
	{
		kernel_data.thread_ctrl_tbl[tid].stack_ptr =
			 kernel_data.thread_ctrl_tbl[tid].stack_base;
 18e:	90 e0       	ldi	r25, 0x00	; 0
 */
void new(uint8_t tid, PTHREAD entry_point, bool enabled)
{
	ATOMIC_BLOCK(ATOMIC_RESTORESTATE)
	{
		kernel_data.thread_ctrl_tbl[tid].stack_ptr =
 190:	8c 01       	movw	r16, r24
 192:	00 0f       	add	r16, r16
 194:	11 1f       	adc	r17, r17
 196:	00 0f       	add	r16, r16
 198:	11 1f       	adc	r17, r17
 19a:	00 0f       	add	r16, r16
 19c:	11 1f       	adc	r17, r17
 19e:	00 50       	subi	r16, 0x00	; 0
 1a0:	1a 4f       	sbci	r17, 0xFA	; 250
			 kernel_data.thread_ctrl_tbl[tid].stack_base;
 1a2:	88 0f       	add	r24, r24
 1a4:	99 1f       	adc	r25, r25
 1a6:	88 0f       	add	r24, r24
 1a8:	99 1f       	adc	r25, r25
 1aa:	88 0f       	add	r24, r24
 1ac:	99 1f       	adc	r25, r25
 1ae:	80 50       	subi	r24, 0x00	; 0
 1b0:	9e 4f       	sbci	r25, 0xFE	; 254
 1b2:	fc 01       	movw	r30, r24
 1b4:	ee 5f       	subi	r30, 0xFE	; 254
 1b6:	fb 4f       	sbci	r31, 0xFB	; 251
 */
void new(uint8_t tid, PTHREAD entry_point, bool enabled)
{
	ATOMIC_BLOCK(ATOMIC_RESTORESTATE)
	{
		kernel_data.thread_ctrl_tbl[tid].stack_ptr =
 1b8:	20 81       	ld	r18, Z
 1ba:	31 81       	ldd	r19, Z+1	; 0x01
 1bc:	f8 01       	movw	r30, r16
 1be:	31 83       	std	Z+1, r19	; 0x01
 1c0:	20 83       	st	Z, r18
			 kernel_data.thread_ctrl_tbl[tid].stack_base;
		kernel_data.thread_ctrl_tbl[tid].entry_pnt = entry_point;
 1c2:	fc 01       	movw	r30, r24
 1c4:	ea 5f       	subi	r30, 0xFA	; 250
 1c6:	fb 4f       	sbci	r31, 0xFB	; 251
 1c8:	71 83       	std	Z+1, r23	; 0x01
 1ca:	60 83       	st	Z, r22
		push_pthread(tid, entry_point);
 1cc:	8c 2f       	mov	r24, r28
 1ce:	b9 df       	rcall	.-142    	; 0x142 <push_pthread>
		kernel_data.thread_ctrl_tbl[tid].stack_ptr -= THREAD_STACK_CONTEXT_SZ;
 1d0:	f8 01       	movw	r30, r16
 1d2:	80 81       	ld	r24, Z
 1d4:	91 81       	ldd	r25, Z+1	; 0x01
 1d6:	9c 01       	movw	r18, r24
 1d8:	21 52       	subi	r18, 0x21	; 33
 1da:	31 09       	sbc	r19, r1
 1dc:	31 83       	std	Z+1, r19	; 0x01
 1de:	20 83       	st	Z, r18
		// for preemptive builds initialize the status register 
		// part of the context to have the interrupt enabled
		#		ifdef PREEMPTIVE
		*(kernel_data.thread_ctrl_tbl[tid].stack_ptr + 1) = 0x80;
 1e0:	fc 01       	movw	r30, r24
 1e2:	b0 97       	sbiw	r30, 0x20	; 32
 1e4:	20 e8       	ldi	r18, 0x80	; 128
 1e6:	20 83       	st	Z, r18
		#		endif /* PREEMPTIVE */
		
		if (enabled)
 1e8:	ff 20       	and	r15, r15
 1ea:	79 f0       	breq	.+30     	; 0x20a <new+0x8e>
		{
			kernel_data.schedule_ctrl.disable_status &= ~(1<<tid);
 1ec:	e0 e4       	ldi	r30, 0x40	; 64
 1ee:	f6 e0       	ldi	r31, 0x06	; 6
 1f0:	81 e0       	ldi	r24, 0x01	; 1
 1f2:	90 e0       	ldi	r25, 0x00	; 0
 1f4:	0c 2e       	mov	r0, r28
 1f6:	02 c0       	rjmp	.+4      	; 0x1fc <new+0x80>
 1f8:	88 0f       	add	r24, r24
 1fa:	99 1f       	adc	r25, r25
 1fc:	0a 94       	dec	r0
 1fe:	e2 f7       	brpl	.-8      	; 0x1f8 <new+0x7c>
 200:	80 95       	com	r24
 202:	90 81       	ld	r25, Z
 204:	89 23       	and	r24, r25
 206:	80 83       	st	Z, r24
 208:	11 c0       	rjmp	.+34     	; 0x22c <new+0xb0>
		}
		else
		{
			kernel_data.schedule_ctrl.disable_status |= 1<<tid;
 20a:	e0 e4       	ldi	r30, 0x40	; 64
 20c:	f6 e0       	ldi	r31, 0x06	; 6
 20e:	81 e0       	ldi	r24, 0x01	; 1
 210:	90 e0       	ldi	r25, 0x00	; 0
 212:	0c 2e       	mov	r0, r28
 214:	02 c0       	rjmp	.+4      	; 0x21a <new+0x9e>
 216:	88 0f       	add	r24, r24
 218:	99 1f       	adc	r25, r25
 21a:	0a 94       	dec	r0
 21c:	e2 f7       	brpl	.-8      	; 0x216 <new+0x9a>
 21e:	90 81       	ld	r25, Z
 220:	89 2b       	or	r24, r25
 222:	80 83       	st	Z, r24
		}
		
		if (kernel_data.schedule_ctrl.cur_thread_id == tid)
		{
			schedule();
 224:	03 c0       	rjmp	.+6      	; 0x22c <new+0xb0>
 226:	c9 d1       	rcall	.+914    	; 0x5ba <schedule>
    (void)__s;
}

static __inline__ void __iRestore(const  uint8_t *__s)
{
    SREG = *__s;
 228:	df bf       	out	0x3f, r29	; 63
		}
	}
}
 22a:	05 c0       	rjmp	.+10     	; 0x236 <new+0xba>
		else
		{
			kernel_data.schedule_ctrl.disable_status |= 1<<tid;
		}
		
		if (kernel_data.schedule_ctrl.cur_thread_id == tid)
 22c:	80 91 52 06 	lds	r24, 0x0652	; 0x800652 <__DATA_REGION_ORIGIN__+0x452>
 230:	c8 17       	cp	r28, r24
 232:	c9 f3       	breq	.-14     	; 0x226 <new+0xaa>
 234:	f9 cf       	rjmp	.-14     	; 0x228 <new+0xac>
		{
			schedule();
		}
	}
}
 236:	df 91       	pop	r29
 238:	cf 91       	pop	r28
 23a:	1f 91       	pop	r17
 23c:	0f 91       	pop	r16
 23e:	ff 90       	pop	r15
 240:	08 95       	ret

00000242 <copy_stack>:
 *	s1_base:	pointer to the base of the stack to be copied
 *	s1_ptr:		the stack pointer of the stack to be copied
 *	s2_ptr:		a pointer to the stack pointer of the stack to be copied to
 */
void copy_stack(uint8_t *s1_base, uint8_t *s1_ptr, volatile uint8_t **s2_ptr)
{
 242:	cf 93       	push	r28
 244:	df 93       	push	r29
 246:	da 01       	movw	r26, r20
	while (s1_base > s1_ptr)
 248:	68 17       	cp	r22, r24
 24a:	79 07       	cpc	r23, r25
 24c:	a0 f4       	brcc	.+40     	; 0x276 <copy_stack+0x34>
 24e:	fc 01       	movw	r30, r24
 250:	31 96       	adiw	r30, 0x01	; 1
 252:	6f 5f       	subi	r22, 0xFF	; 255
 254:	7f 4f       	sbci	r23, 0xFF	; 255
	{
		**s2_ptr = *s1_base;
 256:	cd 91       	ld	r28, X+
 258:	dc 91       	ld	r29, X
 25a:	11 97       	sbiw	r26, 0x01	; 1
 25c:	82 91       	ld	r24, -Z
 25e:	88 83       	st	Y, r24
		--s1_base;
		--(*s2_ptr);
 260:	2d 91       	ld	r18, X+
 262:	3c 91       	ld	r19, X
 264:	11 97       	sbiw	r26, 0x01	; 1
 266:	21 50       	subi	r18, 0x01	; 1
 268:	31 09       	sbc	r19, r1
 26a:	11 96       	adiw	r26, 0x01	; 1
 26c:	3c 93       	st	X, r19
 26e:	2e 93       	st	-X, r18
 *	s1_ptr:		the stack pointer of the stack to be copied
 *	s2_ptr:		a pointer to the stack pointer of the stack to be copied to
 */
void copy_stack(uint8_t *s1_base, uint8_t *s1_ptr, volatile uint8_t **s2_ptr)
{
	while (s1_base > s1_ptr)
 270:	e6 17       	cp	r30, r22
 272:	f7 07       	cpc	r31, r23
 274:	81 f7       	brne	.-32     	; 0x256 <copy_stack+0x14>
	{
		**s2_ptr = *s1_base;
		--s1_base;
		--(*s2_ptr);
	}
 276:	df 91       	pop	r29
 278:	cf 91       	pop	r28
 27a:	08 95       	ret

0000027c <init>:
/*
 *	Initialized the kernel and copies the stack to thread0's stack and returns 
 *	executing in thread0
 */
void init()
{
 27c:	cf 93       	push	r28
 27e:	df 93       	push	r29
    return 1;
}

static __inline__ uint8_t __iCliRetVal(void)
{
    cli();
 280:	f8 94       	cli
	// initialize kernel data and enable interrupts on exit
	ATOMIC_BLOCK(ATOMIC_FORCEON)
	{
		// initialize the thread control structure and stack canary for 
		// each thread
		THREAD_INIT(THREAD0, kernel_data.stacks.stack0, T0_STACKSZ);
 282:	e0 e0       	ldi	r30, 0x00	; 0
 284:	f2 e0       	ldi	r31, 0x02	; 2
 286:	c0 e0       	ldi	r28, 0x00	; 0
 288:	d6 e0       	ldi	r29, 0x06	; 6
 28a:	8f e7       	ldi	r24, 0x7F	; 127
 28c:	92 e0       	ldi	r25, 0x02	; 2
 28e:	99 83       	std	Y+1, r25	; 0x01
 290:	88 83       	st	Y, r24
 292:	90 93 03 06 	sts	0x0603, r25	; 0x800603 <__DATA_REGION_ORIGIN__+0x403>
 296:	80 93 02 06 	sts	0x0602, r24	; 0x800602 <__DATA_REGION_ORIGIN__+0x402>
 29a:	f0 93 05 06 	sts	0x0605, r31	; 0x800605 <__DATA_REGION_ORIGIN__+0x405>
 29e:	e0 93 04 06 	sts	0x0604, r30	; 0x800604 <__DATA_REGION_ORIGIN__+0x404>
 2a2:	2a ea       	ldi	r18, 0xAA	; 170
 2a4:	20 83       	st	Z, r18
 2a6:	83 e9       	ldi	r24, 0x93	; 147
 2a8:	90 e0       	ldi	r25, 0x00	; 0
 2aa:	90 93 07 06 	sts	0x0607, r25	; 0x800607 <__DATA_REGION_ORIGIN__+0x407>
 2ae:	80 93 06 06 	sts	0x0606, r24	; 0x800606 <__DATA_REGION_ORIGIN__+0x406>
		THREAD_INIT(THREAD1, kernel_data.stacks.stack1, T1_STACKSZ);
 2b2:	4f ef       	ldi	r20, 0xFF	; 255
 2b4:	52 e0       	ldi	r21, 0x02	; 2
 2b6:	50 93 09 06 	sts	0x0609, r21	; 0x800609 <__DATA_REGION_ORIGIN__+0x409>
 2ba:	40 93 08 06 	sts	0x0608, r20	; 0x800608 <__DATA_REGION_ORIGIN__+0x408>
 2be:	50 93 0b 06 	sts	0x060B, r21	; 0x80060b <__DATA_REGION_ORIGIN__+0x40b>
 2c2:	40 93 0a 06 	sts	0x060A, r20	; 0x80060a <__DATA_REGION_ORIGIN__+0x40a>
 2c6:	e0 e8       	ldi	r30, 0x80	; 128
 2c8:	f2 e0       	ldi	r31, 0x02	; 2
 2ca:	f0 93 0d 06 	sts	0x060D, r31	; 0x80060d <__DATA_REGION_ORIGIN__+0x40d>
 2ce:	e0 93 0c 06 	sts	0x060C, r30	; 0x80060c <__DATA_REGION_ORIGIN__+0x40c>
 2d2:	20 83       	st	Z, r18
 2d4:	90 93 0f 06 	sts	0x060F, r25	; 0x80060f <__DATA_REGION_ORIGIN__+0x40f>
 2d8:	80 93 0e 06 	sts	0x060E, r24	; 0x80060e <__DATA_REGION_ORIGIN__+0x40e>
		THREAD_INIT(THREAD2, kernel_data.stacks.stack2, T2_STACKSZ);
 2dc:	4f e7       	ldi	r20, 0x7F	; 127
 2de:	53 e0       	ldi	r21, 0x03	; 3
 2e0:	50 93 11 06 	sts	0x0611, r21	; 0x800611 <__DATA_REGION_ORIGIN__+0x411>
 2e4:	40 93 10 06 	sts	0x0610, r20	; 0x800610 <__DATA_REGION_ORIGIN__+0x410>
 2e8:	50 93 13 06 	sts	0x0613, r21	; 0x800613 <__DATA_REGION_ORIGIN__+0x413>
 2ec:	40 93 12 06 	sts	0x0612, r20	; 0x800612 <__DATA_REGION_ORIGIN__+0x412>
 2f0:	e0 e0       	ldi	r30, 0x00	; 0
 2f2:	f3 e0       	ldi	r31, 0x03	; 3
 2f4:	f0 93 15 06 	sts	0x0615, r31	; 0x800615 <__DATA_REGION_ORIGIN__+0x415>
 2f8:	e0 93 14 06 	sts	0x0614, r30	; 0x800614 <__DATA_REGION_ORIGIN__+0x414>
 2fc:	20 83       	st	Z, r18
 2fe:	90 93 17 06 	sts	0x0617, r25	; 0x800617 <__DATA_REGION_ORIGIN__+0x417>
 302:	80 93 16 06 	sts	0x0616, r24	; 0x800616 <__DATA_REGION_ORIGIN__+0x416>
		THREAD_INIT(THREAD3, kernel_data.stacks.stack3, T3_STACKSZ);
 306:	4f ef       	ldi	r20, 0xFF	; 255
 308:	53 e0       	ldi	r21, 0x03	; 3
 30a:	50 93 19 06 	sts	0x0619, r21	; 0x800619 <__DATA_REGION_ORIGIN__+0x419>
 30e:	40 93 18 06 	sts	0x0618, r20	; 0x800618 <__DATA_REGION_ORIGIN__+0x418>
 312:	50 93 1b 06 	sts	0x061B, r21	; 0x80061b <__DATA_REGION_ORIGIN__+0x41b>
 316:	40 93 1a 06 	sts	0x061A, r20	; 0x80061a <__DATA_REGION_ORIGIN__+0x41a>
 31a:	e0 e8       	ldi	r30, 0x80	; 128
 31c:	f3 e0       	ldi	r31, 0x03	; 3
 31e:	f0 93 1d 06 	sts	0x061D, r31	; 0x80061d <__DATA_REGION_ORIGIN__+0x41d>
 322:	e0 93 1c 06 	sts	0x061C, r30	; 0x80061c <__DATA_REGION_ORIGIN__+0x41c>
 326:	20 83       	st	Z, r18
 328:	90 93 1f 06 	sts	0x061F, r25	; 0x80061f <__DATA_REGION_ORIGIN__+0x41f>
 32c:	80 93 1e 06 	sts	0x061E, r24	; 0x80061e <__DATA_REGION_ORIGIN__+0x41e>
		THREAD_INIT(THREAD4, kernel_data.stacks.stack4, T4_STACKSZ);
 330:	4f e7       	ldi	r20, 0x7F	; 127
 332:	54 e0       	ldi	r21, 0x04	; 4
 334:	50 93 21 06 	sts	0x0621, r21	; 0x800621 <__DATA_REGION_ORIGIN__+0x421>
 338:	40 93 20 06 	sts	0x0620, r20	; 0x800620 <__DATA_REGION_ORIGIN__+0x420>
 33c:	50 93 23 06 	sts	0x0623, r21	; 0x800623 <__DATA_REGION_ORIGIN__+0x423>
 340:	40 93 22 06 	sts	0x0622, r20	; 0x800622 <__DATA_REGION_ORIGIN__+0x422>
 344:	e0 e0       	ldi	r30, 0x00	; 0
 346:	f4 e0       	ldi	r31, 0x04	; 4
 348:	f0 93 25 06 	sts	0x0625, r31	; 0x800625 <__DATA_REGION_ORIGIN__+0x425>
 34c:	e0 93 24 06 	sts	0x0624, r30	; 0x800624 <__DATA_REGION_ORIGIN__+0x424>
 350:	20 83       	st	Z, r18
 352:	90 93 27 06 	sts	0x0627, r25	; 0x800627 <__DATA_REGION_ORIGIN__+0x427>
 356:	80 93 26 06 	sts	0x0626, r24	; 0x800626 <__DATA_REGION_ORIGIN__+0x426>
		THREAD_INIT(THREAD5, kernel_data.stacks.stack5, T5_STACKSZ);
 35a:	4f ef       	ldi	r20, 0xFF	; 255
 35c:	54 e0       	ldi	r21, 0x04	; 4
 35e:	50 93 29 06 	sts	0x0629, r21	; 0x800629 <__DATA_REGION_ORIGIN__+0x429>
 362:	40 93 28 06 	sts	0x0628, r20	; 0x800628 <__DATA_REGION_ORIGIN__+0x428>
 366:	50 93 2b 06 	sts	0x062B, r21	; 0x80062b <__DATA_REGION_ORIGIN__+0x42b>
 36a:	40 93 2a 06 	sts	0x062A, r20	; 0x80062a <__DATA_REGION_ORIGIN__+0x42a>
 36e:	e0 e8       	ldi	r30, 0x80	; 128
 370:	f4 e0       	ldi	r31, 0x04	; 4
 372:	f0 93 2d 06 	sts	0x062D, r31	; 0x80062d <__DATA_REGION_ORIGIN__+0x42d>
 376:	e0 93 2c 06 	sts	0x062C, r30	; 0x80062c <__DATA_REGION_ORIGIN__+0x42c>
 37a:	20 83       	st	Z, r18
 37c:	90 93 2f 06 	sts	0x062F, r25	; 0x80062f <__DATA_REGION_ORIGIN__+0x42f>
 380:	80 93 2e 06 	sts	0x062E, r24	; 0x80062e <__DATA_REGION_ORIGIN__+0x42e>
		THREAD_INIT(THREAD6, kernel_data.stacks.stack6, T6_STACKSZ);
 384:	4f e7       	ldi	r20, 0x7F	; 127
 386:	55 e0       	ldi	r21, 0x05	; 5
 388:	50 93 31 06 	sts	0x0631, r21	; 0x800631 <__DATA_REGION_ORIGIN__+0x431>
 38c:	40 93 30 06 	sts	0x0630, r20	; 0x800630 <__DATA_REGION_ORIGIN__+0x430>
 390:	50 93 33 06 	sts	0x0633, r21	; 0x800633 <__DATA_REGION_ORIGIN__+0x433>
 394:	40 93 32 06 	sts	0x0632, r20	; 0x800632 <__DATA_REGION_ORIGIN__+0x432>
 398:	e0 e0       	ldi	r30, 0x00	; 0
 39a:	f5 e0       	ldi	r31, 0x05	; 5
 39c:	f0 93 35 06 	sts	0x0635, r31	; 0x800635 <__DATA_REGION_ORIGIN__+0x435>
 3a0:	e0 93 34 06 	sts	0x0634, r30	; 0x800634 <__DATA_REGION_ORIGIN__+0x434>
 3a4:	20 83       	st	Z, r18
 3a6:	90 93 37 06 	sts	0x0637, r25	; 0x800637 <__DATA_REGION_ORIGIN__+0x437>
 3aa:	80 93 36 06 	sts	0x0636, r24	; 0x800636 <__DATA_REGION_ORIGIN__+0x436>
		THREAD_INIT(THREAD7, kernel_data.stacks.stack7, T7_STACKSZ);
 3ae:	4f ef       	ldi	r20, 0xFF	; 255
 3b0:	55 e0       	ldi	r21, 0x05	; 5
 3b2:	50 93 39 06 	sts	0x0639, r21	; 0x800639 <__DATA_REGION_ORIGIN__+0x439>
 3b6:	40 93 38 06 	sts	0x0638, r20	; 0x800638 <__DATA_REGION_ORIGIN__+0x438>
 3ba:	50 93 3b 06 	sts	0x063B, r21	; 0x80063b <__DATA_REGION_ORIGIN__+0x43b>
 3be:	40 93 3a 06 	sts	0x063A, r20	; 0x80063a <__DATA_REGION_ORIGIN__+0x43a>
 3c2:	e0 e8       	ldi	r30, 0x80	; 128
 3c4:	f5 e0       	ldi	r31, 0x05	; 5
 3c6:	f0 93 3d 06 	sts	0x063D, r31	; 0x80063d <__DATA_REGION_ORIGIN__+0x43d>
 3ca:	e0 93 3c 06 	sts	0x063C, r30	; 0x80063c <__DATA_REGION_ORIGIN__+0x43c>
 3ce:	20 83       	st	Z, r18
 3d0:	90 93 3f 06 	sts	0x063F, r25	; 0x80063f <__DATA_REGION_ORIGIN__+0x43f>
 3d4:	80 93 3e 06 	sts	0x063E, r24	; 0x80063e <__DATA_REGION_ORIGIN__+0x43e>
		
		// copy the stack to the thread 0 stack and set the stack pointer 
		// register to thread0's stack pointer
		copy_stack(GCC_STACK_BASE, *(uint8_t **)STACK_POINTER
 3d8:	6d b7       	in	r22, 0x3d	; 61
 3da:	7e b7       	in	r23, 0x3e	; 62
 3dc:	ae 01       	movw	r20, r28
 3de:	8f ef       	ldi	r24, 0xFF	; 255
 3e0:	91 e2       	ldi	r25, 0x21	; 33
 3e2:	2f df       	rcall	.-418    	; 0x242 <copy_stack>
				, &(kernel_data.thread_ctrl_tbl[THREAD0].stack_ptr));
		*STACK_POINTER = kernel_data.thread_ctrl_tbl[THREAD0].stack_ptr;
 3e4:	88 81       	ld	r24, Y
 3e6:	99 81       	ldd	r25, Y+1	; 0x01
 3e8:	9e bf       	out	0x3e, r25	; 62
 3ea:	8d bf       	out	0x3d, r24	; 61
		
		// initialize the disable status to disable all but thread  0
		kernel_data.schedule_ctrl.disable_status = 
 3ec:	8e ef       	ldi	r24, 0xFE	; 254
 3ee:	80 93 40 06 	sts	0x0640, r24	; 0x800640 <__DATA_REGION_ORIGIN__+0x440>
			THREAD1_MSK | THREAD2_MSK | THREAD3_MSK | THREAD4_MSK 
		  | THREAD5_MSK | THREAD6_MSK | THREAD7_MSK;
		// initialize the delay_status so no threads are delayed
		kernel_data.schedule_ctrl.delay_status = 0x00;
 3f2:	10 92 41 06 	sts	0x0641, r1	; 0x800641 <__DATA_REGION_ORIGIN__+0x441>
		// initialize the current thread and current thread mask to thread0
		kernel_data.schedule_ctrl.cur_thread_id = THREAD0;
 3f6:	10 92 52 06 	sts	0x0652, r1	; 0x800652 <__DATA_REGION_ORIGIN__+0x452>
		kernel_data.schedule_ctrl.cur_thread_msk = THREAD0_MSK;
 3fa:	81 e0       	ldi	r24, 0x01	; 1
 3fc:	80 93 53 06 	sts	0x0653, r24	; 0x800653 <__DATA_REGION_ORIGIN__+0x453>
		
		// initialize other functionality
		
		init_system_timer();
 400:	57 d0       	rcall	.+174    	; 0x4b0 <init_system_timer>
    return 1;
}

static __inline__ void __iSeiParam(const uint8_t *__s)
{
    sei();
 402:	78 94       	sei
		#	ifdef SERIAL
		init_serial();
		#	endif /* SERIAL */
	}
}
 404:	df 91       	pop	r29
 406:	cf 91       	pop	r28
 408:	08 95       	ret

0000040a <__vector_13>:
 *	Unlock the thread to allow the scheduler to be invoked preemptively.
 */
void unlock()
{
	// set the timer compare match B interrupt mask
	TIMSK2 |= (0b1 << OCIE2B);
 40a:	1f 92       	push	r1
 40c:	0f 92       	push	r0
 40e:	0f b6       	in	r0, 0x3f	; 63
 410:	0f 92       	push	r0
 412:	11 24       	eor	r1, r1
 414:	0b b6       	in	r0, 0x3b	; 59
 416:	0f 92       	push	r0
 418:	2f 93       	push	r18
 41a:	3f 93       	push	r19
 41c:	4f 93       	push	r20
 41e:	6f 93       	push	r22
 420:	7f 93       	push	r23
 422:	8f 93       	push	r24
 424:	9f 93       	push	r25
 426:	af 93       	push	r26
 428:	bf 93       	push	r27
 42a:	ef 93       	push	r30
 42c:	ff 93       	push	r31
 42e:	e3 eb       	ldi	r30, 0xB3	; 179
 430:	f0 e0       	ldi	r31, 0x00	; 0
 432:	80 81       	ld	r24, Z
 434:	84 58       	subi	r24, 0x84	; 132
 436:	80 83       	st	Z, r24
 438:	40 91 41 06 	lds	r20, 0x0641	; 0x800641 <__DATA_REGION_ORIGIN__+0x441>
 43c:	e2 e4       	ldi	r30, 0x42	; 66
 43e:	f6 e0       	ldi	r31, 0x06	; 6
 440:	62 e5       	ldi	r22, 0x52	; 82
 442:	76 e0       	ldi	r23, 0x06	; 6
 444:	81 e0       	ldi	r24, 0x01	; 1
 446:	94 2f       	mov	r25, r20
 448:	98 23       	and	r25, r24
 44a:	59 f0       	breq	.+22     	; 0x462 <__vector_13+0x58>
 44c:	20 81       	ld	r18, Z
 44e:	31 81       	ldd	r19, Z+1	; 0x01
 450:	21 50       	subi	r18, 0x01	; 1
 452:	31 09       	sbc	r19, r1
 454:	31 83       	std	Z+1, r19	; 0x01
 456:	20 83       	st	Z, r18
 458:	23 2b       	or	r18, r19
 45a:	19 f4       	brne	.+6      	; 0x462 <__vector_13+0x58>
 45c:	98 2f       	mov	r25, r24
 45e:	90 95       	com	r25
 460:	49 23       	and	r20, r25
 462:	88 0f       	add	r24, r24
 464:	32 96       	adiw	r30, 0x02	; 2
 466:	e6 17       	cp	r30, r22
 468:	f7 07       	cpc	r31, r23
 46a:	69 f7       	brne	.-38     	; 0x446 <__vector_13+0x3c>
 46c:	40 93 41 06 	sts	0x0641, r20	; 0x800641 <__DATA_REGION_ORIGIN__+0x441>
 470:	e4 e5       	ldi	r30, 0x54	; 84
 472:	f6 e0       	ldi	r31, 0x06	; 6
 474:	80 81       	ld	r24, Z
 476:	91 81       	ldd	r25, Z+1	; 0x01
 478:	a2 81       	ldd	r26, Z+2	; 0x02
 47a:	b3 81       	ldd	r27, Z+3	; 0x03
 47c:	01 96       	adiw	r24, 0x01	; 1
 47e:	a1 1d       	adc	r26, r1
 480:	b1 1d       	adc	r27, r1
 482:	80 83       	st	Z, r24
 484:	91 83       	std	Z+1, r25	; 0x01
 486:	a2 83       	std	Z+2, r26	; 0x02
 488:	b3 83       	std	Z+3, r27	; 0x03
 48a:	ff 91       	pop	r31
 48c:	ef 91       	pop	r30
 48e:	bf 91       	pop	r27
 490:	af 91       	pop	r26
 492:	9f 91       	pop	r25
 494:	8f 91       	pop	r24
 496:	7f 91       	pop	r23
 498:	6f 91       	pop	r22
 49a:	4f 91       	pop	r20
 49c:	3f 91       	pop	r19
 49e:	2f 91       	pop	r18
 4a0:	0f 90       	pop	r0
 4a2:	0b be       	out	0x3b, r0	; 59
 4a4:	0f 90       	pop	r0
 4a6:	0f be       	out	0x3f, r0	; 63
 4a8:	0f 90       	pop	r0
 4aa:	1f 90       	pop	r1
 4ac:	18 95       	reti

000004ae <__vector_14>:
 4ae:	17 c0       	rjmp	.+46     	; 0x4de <save_context>

000004b0 <init_system_timer>:
 4b0:	10 92 b0 00 	sts	0x00B0, r1	; 0x8000b0 <__TEXT_REGION_LENGTH__+0x7c00b0>
 4b4:	85 e0       	ldi	r24, 0x05	; 5
 4b6:	80 93 b1 00 	sts	0x00B1, r24	; 0x8000b1 <__TEXT_REGION_LENGTH__+0x7c00b1>
 4ba:	8c e7       	ldi	r24, 0x7C	; 124
 4bc:	80 93 b3 00 	sts	0x00B3, r24	; 0x8000b3 <__TEXT_REGION_LENGTH__+0x7c00b3>
 4c0:	8f e7       	ldi	r24, 0x7F	; 127
 4c2:	80 93 b4 00 	sts	0x00B4, r24	; 0x8000b4 <__TEXT_REGION_LENGTH__+0x7c00b4>
 4c6:	86 e0       	ldi	r24, 0x06	; 6
 4c8:	80 93 70 00 	sts	0x0070, r24	; 0x800070 <__TEXT_REGION_LENGTH__+0x7c0070>
 4cc:	10 92 54 06 	sts	0x0654, r1	; 0x800654 <__DATA_REGION_ORIGIN__+0x454>
 4d0:	10 92 55 06 	sts	0x0655, r1	; 0x800655 <__DATA_REGION_ORIGIN__+0x455>
 4d4:	10 92 56 06 	sts	0x0656, r1	; 0x800656 <__DATA_REGION_ORIGIN__+0x456>
 4d8:	10 92 57 06 	sts	0x0657, r1	; 0x800657 <__DATA_REGION_ORIGIN__+0x457>
 4dc:	08 95       	ret

000004de <save_context>:
 *	This function enters scheduler after completion.
 */
void __attribute__ ((naked)) save_context()
{	
	// save general purpose registers to stack
	asm volatile ("push r0\n\
 4de:	0f 92       	push	r0
 4e0:	1f 92       	push	r1
 4e2:	2f 92       	push	r2
 4e4:	3f 92       	push	r3
 4e6:	4f 92       	push	r4
 4e8:	5f 92       	push	r5
 4ea:	6f 92       	push	r6
 4ec:	7f 92       	push	r7
 4ee:	8f 92       	push	r8
 4f0:	9f 92       	push	r9
 4f2:	af 92       	push	r10
 4f4:	bf 92       	push	r11
 4f6:	cf 92       	push	r12
 4f8:	df 92       	push	r13
 4fa:	ef 92       	push	r14
 4fc:	ff 92       	push	r15
 4fe:	0f 93       	push	r16
 500:	1f 93       	push	r17
 502:	2f 93       	push	r18
 504:	3f 93       	push	r19
 506:	4f 93       	push	r20
 508:	5f 93       	push	r21
 50a:	6f 93       	push	r22
 50c:	7f 93       	push	r23
 50e:	8f 93       	push	r24
 510:	9f 93       	push	r25
 512:	af 93       	push	r26
 514:	bf 93       	push	r27
 516:	cf 93       	push	r28
 518:	df 93       	push	r29
 51a:	ef 93       	push	r30
 51c:	ff 93       	push	r31
				   push r29\n\
				   push r30\n\
				   push r31");
	
	// save status register
	asm volatile ("in r0, 0x3f\n\
 51e:	0f b6       	in	r0, 0x3f	; 63
 520:	0f 92       	push	r0
				   push r0");
	
	//	save stack pointer		   
	kernel_data.thread_ctrl_tbl[kernel_data.schedule_ctrl.cur_thread_id].stack_ptr = 
		*STACK_POINTER;
 522:	8d b7       	in	r24, 0x3d	; 61
 524:	9e b7       	in	r25, 0x3e	; 62
	// save status register
	asm volatile ("in r0, 0x3f\n\
				   push r0");
	
	//	save stack pointer		   
	kernel_data.thread_ctrl_tbl[kernel_data.schedule_ctrl.cur_thread_id].stack_ptr = 
 526:	e0 91 52 06 	lds	r30, 0x0652	; 0x800652 <__DATA_REGION_ORIGIN__+0x452>
 52a:	f0 e0       	ldi	r31, 0x00	; 0
 52c:	ee 0f       	add	r30, r30
 52e:	ff 1f       	adc	r31, r31
 530:	ee 0f       	add	r30, r30
 532:	ff 1f       	adc	r31, r31
 534:	ee 0f       	add	r30, r30
 536:	ff 1f       	adc	r31, r31
 538:	e0 50       	subi	r30, 0x00	; 0
 53a:	fa 4f       	sbci	r31, 0xFA	; 250
 53c:	91 83       	std	Z+1, r25	; 0x01
 53e:	80 83       	st	Z, r24
		*STACK_POINTER;
	
	// jump to the scheduler
	asm volatile ("rjmp schedule");
 540:	3c c0       	rjmp	.+120    	; 0x5ba <schedule>

00000542 <restore_context>:
 *	Is invoked after the scheduler runs.
 */
void __attribute__ ((naked)) restore_context()
{
	// increment OCR2B to match on at the end of the next time slice
	OCR2B = TCNT2 + (TIME_SLICE / TIMER2_PRESCALLER - 1);
 542:	80 91 b2 00 	lds	r24, 0x00B2	; 0x8000b2 <__TEXT_REGION_LENGTH__+0x7c00b2>
 546:	81 58       	subi	r24, 0x81	; 129
 548:	80 93 b4 00 	sts	0x00B4, r24	; 0x8000b4 <__TEXT_REGION_LENGTH__+0x7c00b4>
	
	// enable the TIMER2_COMPB interrupt to allow for rescheduling
	TIMSK2 |= 0b1<<OCIE2B;
 54c:	e0 e7       	ldi	r30, 0x70	; 112
 54e:	f0 e0       	ldi	r31, 0x00	; 0
 550:	80 81       	ld	r24, Z
 552:	84 60       	ori	r24, 0x04	; 4
 554:	80 83       	st	Z, r24
	
	// restore stack pointer
	*STACK_POINTER = 
		kernel_data.thread_ctrl_tbl[kernel_data.schedule_ctrl.cur_thread_id].stack_ptr;
 556:	e0 91 52 06 	lds	r30, 0x0652	; 0x800652 <__DATA_REGION_ORIGIN__+0x452>
 55a:	f0 e0       	ldi	r31, 0x00	; 0
 55c:	ee 0f       	add	r30, r30
 55e:	ff 1f       	adc	r31, r31
 560:	ee 0f       	add	r30, r30
 562:	ff 1f       	adc	r31, r31
 564:	ee 0f       	add	r30, r30
 566:	ff 1f       	adc	r31, r31
 568:	e0 50       	subi	r30, 0x00	; 0
 56a:	fa 4f       	sbci	r31, 0xFA	; 250
 56c:	80 81       	ld	r24, Z
 56e:	91 81       	ldd	r25, Z+1	; 0x01
	
	// enable the TIMER2_COMPB interrupt to allow for rescheduling
	TIMSK2 |= 0b1<<OCIE2B;
	
	// restore stack pointer
	*STACK_POINTER = 
 570:	9e bf       	out	0x3e, r25	; 62
 572:	8d bf       	out	0x3d, r24	; 61
		kernel_data.thread_ctrl_tbl[kernel_data.schedule_ctrl.cur_thread_id].stack_ptr;
	
	// restore status register
	asm volatile ("pop r0\n\
 574:	0f 90       	pop	r0
 576:	0f be       	out	0x3f, r0	; 63
				   out 0x3f, r0");
	
	// restore general purpose registers
	asm volatile ("pop r31\n\
 578:	ff 91       	pop	r31
 57a:	ef 91       	pop	r30
 57c:	df 91       	pop	r29
 57e:	cf 91       	pop	r28
 580:	bf 91       	pop	r27
 582:	af 91       	pop	r26
 584:	9f 91       	pop	r25
 586:	8f 91       	pop	r24
 588:	7f 91       	pop	r23
 58a:	6f 91       	pop	r22
 58c:	5f 91       	pop	r21
 58e:	4f 91       	pop	r20
 590:	3f 91       	pop	r19
 592:	2f 91       	pop	r18
 594:	1f 91       	pop	r17
 596:	0f 91       	pop	r16
 598:	ff 90       	pop	r15
 59a:	ef 90       	pop	r14
 59c:	df 90       	pop	r13
 59e:	cf 90       	pop	r12
 5a0:	bf 90       	pop	r11
 5a2:	af 90       	pop	r10
 5a4:	9f 90       	pop	r9
 5a6:	8f 90       	pop	r8
 5a8:	7f 90       	pop	r7
 5aa:	6f 90       	pop	r6
 5ac:	5f 90       	pop	r5
 5ae:	4f 90       	pop	r4
 5b0:	3f 90       	pop	r3
 5b2:	2f 90       	pop	r2
 5b4:	1f 90       	pop	r1
 5b6:	0f 90       	pop	r0
				   pop r2\n\
				   pop r1\n\
				   pop r0");
	
	// the next address on the stack should be the address of the next instruction tobe executed in the current thread
	asm volatile ("reti");
 5b8:	18 95       	reti

000005ba <schedule>:
 */
void __attribute__ ((naked)) schedule()
{
	// disable TIMER2_COMPB interrupt to prevent the scheduler from being invoked 
	// during sleep
	TIMSK2 &= ~(0b1<<OCIE2B);
 5ba:	e0 e7       	ldi	r30, 0x70	; 112
 5bc:	f0 e0       	ldi	r31, 0x00	; 0
 5be:	80 81       	ld	r24, Z
 5c0:	8b 7f       	andi	r24, 0xFB	; 251
 5c2:	80 83       	st	Z, r24
	
	// verify canary
	if (*(kernel_data.thread_ctrl_tbl[kernel_data.schedule_ctrl.cur_thread_id].canary_ptr) != CANARY)
 5c4:	e0 91 52 06 	lds	r30, 0x0652	; 0x800652 <__DATA_REGION_ORIGIN__+0x452>
 5c8:	f0 e0       	ldi	r31, 0x00	; 0
 5ca:	ee 0f       	add	r30, r30
 5cc:	ff 1f       	adc	r31, r31
 5ce:	ee 0f       	add	r30, r30
 5d0:	ff 1f       	adc	r31, r31
 5d2:	ee 0f       	add	r30, r30
 5d4:	ff 1f       	adc	r31, r31
 5d6:	ec 5f       	subi	r30, 0xFC	; 252
 5d8:	f9 4f       	sbci	r31, 0xF9	; 249
 5da:	01 90       	ld	r0, Z+
 5dc:	f0 81       	ld	r31, Z
 5de:	e0 2d       	mov	r30, r0
 5e0:	80 81       	ld	r24, Z
 5e2:	8a 3a       	cpi	r24, 0xAA	; 170
 5e4:	09 f0       	breq	.+2      	; 0x5e8 <schedule+0x2e>
	{
		stack_overflow();
 5e6:	91 dd       	rcall	.-1246   	; 0x10a <stack_overflow>
	
	// compute ready status and sleep if no threads are ready
	uint8_t ready_status;
	do
	{
		ready_status = kernel_data.schedule_ctrl.disable_status;
 5e8:	a0 e4       	ldi	r26, 0x40	; 64
 5ea:	b6 e0       	ldi	r27, 0x06	; 6
		ready_status |= kernel_data.schedule_ctrl.delay_status;
 5ec:	e1 e4       	ldi	r30, 0x41	; 65
 5ee:	f6 e0       	ldi	r31, 0x06	; 6
		ready_status = ~ready_status;
		if (!ready_status)
		{
			// enter the extended standby sleep mode if no threads are ready
			SMCR = SLEEP_MODE_EXT_STANDBY | (0b1 << SE);
 5f0:	2f e0       	ldi	r18, 0x0F	; 15
	
	// compute ready status and sleep if no threads are ready
	uint8_t ready_status;
	do
	{
		ready_status = kernel_data.schedule_ctrl.disable_status;
 5f2:	9c 91       	ld	r25, X
		ready_status |= kernel_data.schedule_ctrl.delay_status;
 5f4:	80 81       	ld	r24, Z
 5f6:	89 2b       	or	r24, r25
		ready_status = ~ready_status;
 5f8:	80 95       	com	r24
		if (!ready_status)
 5fa:	29 f4       	brne	.+10     	; 0x606 <schedule+0x4c>
		{
			// enter the extended standby sleep mode if no threads are ready
			SMCR = SLEEP_MODE_EXT_STANDBY | (0b1 << SE);
 5fc:	23 bf       	out	0x33, r18	; 51
			sei();
 5fe:	78 94       	sei
			asm volatile ("sleep");
 600:	88 95       	sleep
			cli();
 602:	f8 94       	cli
 604:	f6 cf       	rjmp	.-20     	; 0x5f2 <schedule+0x38>
	} while (!ready_status);
	
	// schedule the next thread
	do
	{
		kernel_data.schedule_ctrl.cur_thread_id = (kernel_data.schedule_ctrl.cur_thread_id + 1) & 0x07;
 606:	a2 e5       	ldi	r26, 0x52	; 82
 608:	b6 e0       	ldi	r27, 0x06	; 6
		asm volatile ("lsl %1\n\
					   clr r1\n\
					   adc %1, r1"
					   : "=r" (kernel_data.schedule_ctrl.cur_thread_msk)
					   : "r" (kernel_data.schedule_ctrl.cur_thread_msk));
 60a:	e3 e5       	ldi	r30, 0x53	; 83
 60c:	f6 e0       	ldi	r31, 0x06	; 6
	} while (!ready_status);
	
	// schedule the next thread
	do
	{
		kernel_data.schedule_ctrl.cur_thread_id = (kernel_data.schedule_ctrl.cur_thread_id + 1) & 0x07;
 60e:	9c 91       	ld	r25, X
 610:	9f 5f       	subi	r25, 0xFF	; 255
 612:	97 70       	andi	r25, 0x07	; 7
 614:	9c 93       	st	X, r25
		asm volatile ("lsl %1\n\
 616:	90 81       	ld	r25, Z
 618:	99 0f       	add	r25, r25
 61a:	11 24       	eor	r1, r1
 61c:	91 1d       	adc	r25, r1
 61e:	90 83       	st	Z, r25
					   clr r1\n\
					   adc %1, r1"
					   : "=r" (kernel_data.schedule_ctrl.cur_thread_msk)
					   : "r" (kernel_data.schedule_ctrl.cur_thread_msk));
	} while (!(kernel_data.schedule_ctrl.cur_thread_msk & ready_status));
 620:	98 23       	and	r25, r24
 622:	a9 f3       	breq	.-22     	; 0x60e <schedule+0x54>
	
	// jump to restore the new current thread's context
	asm volatile ("rjmp restore_context");
 624:	8e cf       	rjmp	.-228    	; 0x542 <restore_context>

00000626 <t0>:
		delay(5);
	}
}

void t2()
{
 626:	ff cf       	rjmp	.-2      	; 0x626 <t0>

00000628 <main>:
	}
}

int main(void)
{
	init();
 628:	29 de       	rcall	.-942    	; 0x27c <init>
// 	new(5, t0, true);
// 	new(4, t0, true);
// 	new(3, t0, true);
// 	new(2, t0, true);
// 	new(1, t0, true);
	new(0, t0, true);
 62a:	41 e0       	ldi	r20, 0x01	; 1
 62c:	63 e1       	ldi	r22, 0x13	; 19
 62e:	73 e0       	ldi	r23, 0x03	; 3
 630:	80 e0       	ldi	r24, 0x00	; 0
 632:	a4 dd       	rcall	.-1208   	; 0x17c <new>
}
 634:	80 e0       	ldi	r24, 0x00	; 0
 636:	90 e0       	ldi	r25, 0x00	; 0
 638:	08 95       	ret

0000063a <_exit>:
 63a:	f8 94       	cli

0000063c <__stop_program>:
 63c:	ff cf       	rjmp	.-2      	; 0x63c <__stop_program>
