
Kernel.elf:     file format elf32-avr

Sections:
Idx Name          Size      VMA       LMA       File off  Algn
  0 .data         00000000  00800200  00800200  00000652  2**0
                  CONTENTS, ALLOC, LOAD, DATA
  1 .text         000005de  00000000  00000000  00000074  2**1
                  CONTENTS, ALLOC, LOAD, READONLY, CODE
  2 .bss          00000458  00800200  00800200  00000652  2**0
                  ALLOC
  3 .comment      00000030  00000000  00000000  00000652  2**0
                  CONTENTS, READONLY
  4 .note.gnu.avr.deviceinfo 00000040  00000000  00000000  00000684  2**2
                  CONTENTS, READONLY
  5 .debug_aranges 000000b8  00000000  00000000  000006c4  2**0
                  CONTENTS, READONLY, DEBUGGING
  6 .debug_info   000019ec  00000000  00000000  0000077c  2**0
                  CONTENTS, READONLY, DEBUGGING
  7 .debug_abbrev 00001073  00000000  00000000  00002168  2**0
                  CONTENTS, READONLY, DEBUGGING
  8 .debug_line   0000089e  00000000  00000000  000031db  2**0
                  CONTENTS, READONLY, DEBUGGING
  9 .debug_frame  0000019c  00000000  00000000  00003a7c  2**2
                  CONTENTS, READONLY, DEBUGGING
 10 .debug_str    000007a9  00000000  00000000  00003c18  2**0
                  CONTENTS, READONLY, DEBUGGING
 11 .debug_loc    00000488  00000000  00000000  000043c1  2**0
                  CONTENTS, READONLY, DEBUGGING
 12 .debug_ranges 00000088  00000000  00000000  00004849  2**0
                  CONTENTS, READONLY, DEBUGGING

Disassembly of section .text:

00000000 <__vectors>:
   0:	71 c0       	rjmp	.+226    	; 0xe4 <__ctors_end>
   2:	00 00       	nop
   4:	81 c0       	rjmp	.+258    	; 0x108 <__bad_interrupt>
   6:	00 00       	nop
   8:	7f c0       	rjmp	.+254    	; 0x108 <__bad_interrupt>
   a:	00 00       	nop
   c:	7d c0       	rjmp	.+250    	; 0x108 <__bad_interrupt>
   e:	00 00       	nop
  10:	7b c0       	rjmp	.+246    	; 0x108 <__bad_interrupt>
  12:	00 00       	nop
  14:	79 c0       	rjmp	.+242    	; 0x108 <__bad_interrupt>
  16:	00 00       	nop
  18:	77 c0       	rjmp	.+238    	; 0x108 <__bad_interrupt>
  1a:	00 00       	nop
  1c:	75 c0       	rjmp	.+234    	; 0x108 <__bad_interrupt>
  1e:	00 00       	nop
  20:	73 c0       	rjmp	.+230    	; 0x108 <__bad_interrupt>
  22:	00 00       	nop
  24:	71 c0       	rjmp	.+226    	; 0x108 <__bad_interrupt>
  26:	00 00       	nop
  28:	6f c0       	rjmp	.+222    	; 0x108 <__bad_interrupt>
  2a:	00 00       	nop
  2c:	6d c0       	rjmp	.+218    	; 0x108 <__bad_interrupt>
  2e:	00 00       	nop
  30:	6b c0       	rjmp	.+214    	; 0x108 <__bad_interrupt>
  32:	00 00       	nop
  34:	f7 c1       	rjmp	.+1006   	; 0x424 <__vector_13>
  36:	00 00       	nop
  38:	67 c0       	rjmp	.+206    	; 0x108 <__bad_interrupt>
  3a:	00 00       	nop
  3c:	65 c0       	rjmp	.+202    	; 0x108 <__bad_interrupt>
  3e:	00 00       	nop
  40:	63 c0       	rjmp	.+198    	; 0x108 <__bad_interrupt>
  42:	00 00       	nop
  44:	61 c0       	rjmp	.+194    	; 0x108 <__bad_interrupt>
  46:	00 00       	nop
  48:	5f c0       	rjmp	.+190    	; 0x108 <__bad_interrupt>
  4a:	00 00       	nop
  4c:	5d c0       	rjmp	.+186    	; 0x108 <__bad_interrupt>
  4e:	00 00       	nop
  50:	5b c0       	rjmp	.+182    	; 0x108 <__bad_interrupt>
  52:	00 00       	nop
  54:	59 c0       	rjmp	.+178    	; 0x108 <__bad_interrupt>
  56:	00 00       	nop
  58:	57 c0       	rjmp	.+174    	; 0x108 <__bad_interrupt>
  5a:	00 00       	nop
  5c:	55 c0       	rjmp	.+170    	; 0x108 <__bad_interrupt>
  5e:	00 00       	nop
  60:	53 c0       	rjmp	.+166    	; 0x108 <__bad_interrupt>
  62:	00 00       	nop
  64:	51 c0       	rjmp	.+162    	; 0x108 <__bad_interrupt>
  66:	00 00       	nop
  68:	4f c0       	rjmp	.+158    	; 0x108 <__bad_interrupt>
  6a:	00 00       	nop
  6c:	4d c0       	rjmp	.+154    	; 0x108 <__bad_interrupt>
  6e:	00 00       	nop
  70:	4b c0       	rjmp	.+150    	; 0x108 <__bad_interrupt>
  72:	00 00       	nop
  74:	49 c0       	rjmp	.+146    	; 0x108 <__bad_interrupt>
  76:	00 00       	nop
  78:	47 c0       	rjmp	.+142    	; 0x108 <__bad_interrupt>
  7a:	00 00       	nop
  7c:	45 c0       	rjmp	.+138    	; 0x108 <__bad_interrupt>
  7e:	00 00       	nop
  80:	43 c0       	rjmp	.+134    	; 0x108 <__bad_interrupt>
  82:	00 00       	nop
  84:	41 c0       	rjmp	.+130    	; 0x108 <__bad_interrupt>
  86:	00 00       	nop
  88:	3f c0       	rjmp	.+126    	; 0x108 <__bad_interrupt>
  8a:	00 00       	nop
  8c:	3d c0       	rjmp	.+122    	; 0x108 <__bad_interrupt>
  8e:	00 00       	nop
  90:	3b c0       	rjmp	.+118    	; 0x108 <__bad_interrupt>
  92:	00 00       	nop
  94:	39 c0       	rjmp	.+114    	; 0x108 <__bad_interrupt>
  96:	00 00       	nop
  98:	37 c0       	rjmp	.+110    	; 0x108 <__bad_interrupt>
  9a:	00 00       	nop
  9c:	35 c0       	rjmp	.+106    	; 0x108 <__bad_interrupt>
  9e:	00 00       	nop
  a0:	33 c0       	rjmp	.+102    	; 0x108 <__bad_interrupt>
  a2:	00 00       	nop
  a4:	31 c0       	rjmp	.+98     	; 0x108 <__bad_interrupt>
  a6:	00 00       	nop
  a8:	2f c0       	rjmp	.+94     	; 0x108 <__bad_interrupt>
  aa:	00 00       	nop
  ac:	2d c0       	rjmp	.+90     	; 0x108 <__bad_interrupt>
  ae:	00 00       	nop
  b0:	2b c0       	rjmp	.+86     	; 0x108 <__bad_interrupt>
  b2:	00 00       	nop
  b4:	29 c0       	rjmp	.+82     	; 0x108 <__bad_interrupt>
  b6:	00 00       	nop
  b8:	27 c0       	rjmp	.+78     	; 0x108 <__bad_interrupt>
  ba:	00 00       	nop
  bc:	25 c0       	rjmp	.+74     	; 0x108 <__bad_interrupt>
  be:	00 00       	nop
  c0:	23 c0       	rjmp	.+70     	; 0x108 <__bad_interrupt>
  c2:	00 00       	nop
  c4:	21 c0       	rjmp	.+66     	; 0x108 <__bad_interrupt>
  c6:	00 00       	nop
  c8:	1f c0       	rjmp	.+62     	; 0x108 <__bad_interrupt>
  ca:	00 00       	nop
  cc:	1d c0       	rjmp	.+58     	; 0x108 <__bad_interrupt>
  ce:	00 00       	nop
  d0:	1b c0       	rjmp	.+54     	; 0x108 <__bad_interrupt>
  d2:	00 00       	nop
  d4:	19 c0       	rjmp	.+50     	; 0x108 <__bad_interrupt>
  d6:	00 00       	nop
  d8:	17 c0       	rjmp	.+46     	; 0x108 <__bad_interrupt>
  da:	00 00       	nop
  dc:	15 c0       	rjmp	.+42     	; 0x108 <__bad_interrupt>
  de:	00 00       	nop
  e0:	13 c0       	rjmp	.+38     	; 0x108 <__bad_interrupt>
	...

000000e4 <__ctors_end>:
  e4:	11 24       	eor	r1, r1
  e6:	1f be       	out	0x3f, r1	; 63
  e8:	cf ef       	ldi	r28, 0xFF	; 255
  ea:	d1 e2       	ldi	r29, 0x21	; 33
  ec:	de bf       	out	0x3e, r29	; 62
  ee:	cd bf       	out	0x3d, r28	; 61
  f0:	00 e0       	ldi	r16, 0x00	; 0
  f2:	0c bf       	out	0x3c, r16	; 60

000000f4 <__do_clear_bss>:
  f4:	26 e0       	ldi	r18, 0x06	; 6
  f6:	a0 e0       	ldi	r26, 0x00	; 0
  f8:	b2 e0       	ldi	r27, 0x02	; 2
  fa:	01 c0       	rjmp	.+2      	; 0xfe <.do_clear_bss_start>

000000fc <.do_clear_bss_loop>:
  fc:	1d 92       	st	X+, r1

000000fe <.do_clear_bss_start>:
  fe:	a8 35       	cpi	r26, 0x58	; 88
 100:	b2 07       	cpc	r27, r18
 102:	e1 f7       	brne	.-8      	; 0xfc <.do_clear_bss_loop>
 104:	58 d2       	rcall	.+1200   	; 0x5b6 <main>
 106:	69 c2       	rjmp	.+1234   	; 0x5da <_exit>

00000108 <__bad_interrupt>:
 108:	7b cf       	rjmp	.-266    	; 0x0 <__vectors>

0000010a <init_system_timer>:
	uint8_t cs2 = 0b101;	// use clkt2s/128 prescaller
	uint8_t ocie2a = 0b1;	// enable compare match A interrupt
	uint8_t ocie2b = 0b0;	// disable compare match b interrupt
	uint8_t toie2 = 0b0;	// disable overflow interrupt
	
	TCCR2A = (com2a << COM2A0) | (com2b << COM2B0) | ((wgm2 & 0b11) << WGM20);
 10a:	82 e0       	ldi	r24, 0x02	; 2
 10c:	80 93 b0 00 	sts	0x00B0, r24	; 0x8000b0 <__TEXT_REGION_LENGTH__+0x7c00b0>
	TCCR2B = (foc2a << FOC2A) | (foc2b << FOC2B) | (((wgm2 & 0b100) >> 2) << WGM22) | (cs2 << CS20);
 110:	95 e0       	ldi	r25, 0x05	; 5
 112:	90 93 b1 00 	sts	0x00B1, r25	; 0x8000b1 <__TEXT_REGION_LENGTH__+0x7c00b1>
	OCR2A = (F_CPU / 1000) / 128 - 1;
 116:	9c e7       	ldi	r25, 0x7C	; 124
 118:	90 93 b3 00 	sts	0x00B3, r25	; 0x8000b3 <__TEXT_REGION_LENGTH__+0x7c00b3>
	TIMSK2 = (ocie2a << OCIE2A) | (ocie2b << OCIE2B) | (toie2 << TOIE2);
 11c:	80 93 70 00 	sts	0x0070, r24	; 0x800070 <__TEXT_REGION_LENGTH__+0x7c0070>
	
	// set timer to zero
	kernel_data.system_time_millis = 0;
 120:	10 92 54 06 	sts	0x0654, r1	; 0x800654 <__DATA_REGION_ORIGIN__+0x454>
 124:	10 92 55 06 	sts	0x0655, r1	; 0x800655 <__DATA_REGION_ORIGIN__+0x455>
 128:	10 92 56 06 	sts	0x0656, r1	; 0x800656 <__DATA_REGION_ORIGIN__+0x456>
 12c:	10 92 57 06 	sts	0x0657, r1	; 0x800657 <__DATA_REGION_ORIGIN__+0x457>
 130:	08 95       	ret

00000132 <push_pthread>:
 *	func:	the function pointer to be pushed
 */
void push_pthread(uint8_t tid, PTHREAD func)
{
	// push low order byte
	*(kernel_data.thread_ctrl_tbl[tid].stack_ptr--) = (uint8_t) ((((uint16_t) func) & 0x00ff) >> 0);
 132:	28 e0       	ldi	r18, 0x08	; 8
 134:	82 9f       	mul	r24, r18
 136:	c0 01       	movw	r24, r0
 138:	11 24       	eor	r1, r1
 13a:	fc 01       	movw	r30, r24
 13c:	e0 50       	subi	r30, 0x00	; 0
 13e:	fa 4f       	sbci	r31, 0xFA	; 250
 140:	a0 81       	ld	r26, Z
 142:	b1 81       	ldd	r27, Z+1	; 0x01
 144:	cd 01       	movw	r24, r26
 146:	01 97       	sbiw	r24, 0x01	; 1
 148:	91 83       	std	Z+1, r25	; 0x01
 14a:	80 83       	st	Z, r24
 14c:	6c 93       	st	X, r22
	// push middle order byte
	*(kernel_data.thread_ctrl_tbl[tid].stack_ptr--) = (uint8_t) ((((uint16_t) func) & 0xff00) >> 8);
 14e:	a0 81       	ld	r26, Z
 150:	b1 81       	ldd	r27, Z+1	; 0x01
 152:	cd 01       	movw	r24, r26
 154:	01 97       	sbiw	r24, 0x01	; 1
 156:	91 83       	std	Z+1, r25	; 0x01
 158:	80 83       	st	Z, r24
 15a:	7c 93       	st	X, r23
	// push high order byte
	// because the ATmega2560 has a 17 bit address space for program memory and gcc uses 
	// 16 bit address space, the high order byte is always zero for a function pointer and 
	//trampoline tables are used for functions in high parts of program memory
	*(kernel_data.thread_ctrl_tbl[tid].stack_ptr--) = (uint8_t) (0x00);
 15c:	a0 81       	ld	r26, Z
 15e:	b1 81       	ldd	r27, Z+1	; 0x01
 160:	cd 01       	movw	r24, r26
 162:	01 97       	sbiw	r24, 0x01	; 1
 164:	91 83       	std	Z+1, r25	; 0x01
 166:	80 83       	st	Z, r24
 168:	1c 92       	st	X, r1
 16a:	08 95       	ret

0000016c <init>:

/*
 *	Initializes kernel data structures.
 */
void init()
{	
 16c:	1f 93       	push	r17
 16e:	cf 93       	push	r28
 170:	df 93       	push	r29
	ATOMIC_BLOCK(ATOMIC_RESTORESTATE)
 172:	1f b7       	in	r17, 0x3f	; 63
    return 1;
}

static __inline__ uint8_t __iCliRetVal(void)
{
    cli();
 174:	f8 94       	cli
	{
		// set the stack base pointer for each thread
		kernel_data.thread_ctrl_tbl[0].stack_base = (uint8_t *) (kernel_data.stacks.stack0 + T0_STACKSZ - 1);
 176:	8f e7       	ldi	r24, 0x7F	; 127
 178:	92 e0       	ldi	r25, 0x02	; 2
 17a:	90 93 03 06 	sts	0x0603, r25	; 0x800603 <__DATA_REGION_ORIGIN__+0x403>
 17e:	80 93 02 06 	sts	0x0602, r24	; 0x800602 <__DATA_REGION_ORIGIN__+0x402>
		kernel_data.thread_ctrl_tbl[1].stack_base = (uint8_t *) (kernel_data.stacks.stack1 + T1_STACKSZ - 1);
 182:	8f ef       	ldi	r24, 0xFF	; 255
 184:	92 e0       	ldi	r25, 0x02	; 2
 186:	90 93 0b 06 	sts	0x060B, r25	; 0x80060b <__DATA_REGION_ORIGIN__+0x40b>
 18a:	80 93 0a 06 	sts	0x060A, r24	; 0x80060a <__DATA_REGION_ORIGIN__+0x40a>
		kernel_data.thread_ctrl_tbl[2].stack_base = (uint8_t *) (kernel_data.stacks.stack2 + T2_STACKSZ - 1);
 18e:	8f e7       	ldi	r24, 0x7F	; 127
 190:	93 e0       	ldi	r25, 0x03	; 3
 192:	90 93 13 06 	sts	0x0613, r25	; 0x800613 <__DATA_REGION_ORIGIN__+0x413>
 196:	80 93 12 06 	sts	0x0612, r24	; 0x800612 <__DATA_REGION_ORIGIN__+0x412>
		kernel_data.thread_ctrl_tbl[3].stack_base = (uint8_t *) (kernel_data.stacks.stack3 + T3_STACKSZ - 1);
 19a:	8f ef       	ldi	r24, 0xFF	; 255
 19c:	93 e0       	ldi	r25, 0x03	; 3
 19e:	90 93 1b 06 	sts	0x061B, r25	; 0x80061b <__DATA_REGION_ORIGIN__+0x41b>
 1a2:	80 93 1a 06 	sts	0x061A, r24	; 0x80061a <__DATA_REGION_ORIGIN__+0x41a>
		kernel_data.thread_ctrl_tbl[4].stack_base = (uint8_t *) (kernel_data.stacks.stack4 + T4_STACKSZ - 1);
 1a6:	8f e7       	ldi	r24, 0x7F	; 127
 1a8:	94 e0       	ldi	r25, 0x04	; 4
 1aa:	90 93 23 06 	sts	0x0623, r25	; 0x800623 <__DATA_REGION_ORIGIN__+0x423>
 1ae:	80 93 22 06 	sts	0x0622, r24	; 0x800622 <__DATA_REGION_ORIGIN__+0x422>
		kernel_data.thread_ctrl_tbl[5].stack_base = (uint8_t *) (kernel_data.stacks.stack5 + T5_STACKSZ - 1);
 1b2:	8f ef       	ldi	r24, 0xFF	; 255
 1b4:	94 e0       	ldi	r25, 0x04	; 4
 1b6:	90 93 2b 06 	sts	0x062B, r25	; 0x80062b <__DATA_REGION_ORIGIN__+0x42b>
 1ba:	80 93 2a 06 	sts	0x062A, r24	; 0x80062a <__DATA_REGION_ORIGIN__+0x42a>
		kernel_data.thread_ctrl_tbl[6].stack_base = (uint8_t *) (kernel_data.stacks.stack6 + T6_STACKSZ - 1);
 1be:	8f e7       	ldi	r24, 0x7F	; 127
 1c0:	95 e0       	ldi	r25, 0x05	; 5
 1c2:	90 93 33 06 	sts	0x0633, r25	; 0x800633 <__DATA_REGION_ORIGIN__+0x433>
 1c6:	80 93 32 06 	sts	0x0632, r24	; 0x800632 <__DATA_REGION_ORIGIN__+0x432>
		kernel_data.thread_ctrl_tbl[7].stack_base = (uint8_t *) (kernel_data.stacks.stack7 + T7_STACKSZ - 1);
 1ca:	8f ef       	ldi	r24, 0xFF	; 255
 1cc:	95 e0       	ldi	r25, 0x05	; 5
 1ce:	90 93 3b 06 	sts	0x063B, r25	; 0x80063b <__DATA_REGION_ORIGIN__+0x43b>
 1d2:	80 93 3a 06 	sts	0x063A, r24	; 0x80063a <__DATA_REGION_ORIGIN__+0x43a>
		
		// set stack canary pointer for each thread
		kernel_data.thread_ctrl_tbl[0].canary_ptr = kernel_data.stacks.stack0;
 1d6:	80 e0       	ldi	r24, 0x00	; 0
 1d8:	92 e0       	ldi	r25, 0x02	; 2
 1da:	90 93 05 06 	sts	0x0605, r25	; 0x800605 <__DATA_REGION_ORIGIN__+0x405>
 1de:	80 93 04 06 	sts	0x0604, r24	; 0x800604 <__DATA_REGION_ORIGIN__+0x404>
		kernel_data.thread_ctrl_tbl[1].canary_ptr = kernel_data.stacks.stack1;
 1e2:	80 e8       	ldi	r24, 0x80	; 128
 1e4:	92 e0       	ldi	r25, 0x02	; 2
 1e6:	90 93 0d 06 	sts	0x060D, r25	; 0x80060d <__DATA_REGION_ORIGIN__+0x40d>
 1ea:	80 93 0c 06 	sts	0x060C, r24	; 0x80060c <__DATA_REGION_ORIGIN__+0x40c>
		kernel_data.thread_ctrl_tbl[2].canary_ptr = kernel_data.stacks.stack2;
 1ee:	80 e0       	ldi	r24, 0x00	; 0
 1f0:	93 e0       	ldi	r25, 0x03	; 3
 1f2:	90 93 15 06 	sts	0x0615, r25	; 0x800615 <__DATA_REGION_ORIGIN__+0x415>
 1f6:	80 93 14 06 	sts	0x0614, r24	; 0x800614 <__DATA_REGION_ORIGIN__+0x414>
		kernel_data.thread_ctrl_tbl[3].canary_ptr = kernel_data.stacks.stack3;
 1fa:	80 e8       	ldi	r24, 0x80	; 128
 1fc:	93 e0       	ldi	r25, 0x03	; 3
 1fe:	90 93 1d 06 	sts	0x061D, r25	; 0x80061d <__DATA_REGION_ORIGIN__+0x41d>
 202:	80 93 1c 06 	sts	0x061C, r24	; 0x80061c <__DATA_REGION_ORIGIN__+0x41c>
		kernel_data.thread_ctrl_tbl[4].canary_ptr = kernel_data.stacks.stack4;
 206:	80 e0       	ldi	r24, 0x00	; 0
 208:	94 e0       	ldi	r25, 0x04	; 4
 20a:	90 93 25 06 	sts	0x0625, r25	; 0x800625 <__DATA_REGION_ORIGIN__+0x425>
 20e:	80 93 24 06 	sts	0x0624, r24	; 0x800624 <__DATA_REGION_ORIGIN__+0x424>
		kernel_data.thread_ctrl_tbl[5].canary_ptr = kernel_data.stacks.stack5;
 212:	80 e8       	ldi	r24, 0x80	; 128
 214:	94 e0       	ldi	r25, 0x04	; 4
 216:	90 93 2d 06 	sts	0x062D, r25	; 0x80062d <__DATA_REGION_ORIGIN__+0x42d>
 21a:	80 93 2c 06 	sts	0x062C, r24	; 0x80062c <__DATA_REGION_ORIGIN__+0x42c>
		kernel_data.thread_ctrl_tbl[6].canary_ptr = kernel_data.stacks.stack6;
 21e:	80 e0       	ldi	r24, 0x00	; 0
 220:	95 e0       	ldi	r25, 0x05	; 5
 222:	90 93 35 06 	sts	0x0635, r25	; 0x800635 <__DATA_REGION_ORIGIN__+0x435>
 226:	80 93 34 06 	sts	0x0634, r24	; 0x800634 <__DATA_REGION_ORIGIN__+0x434>
		kernel_data.thread_ctrl_tbl[7].canary_ptr = kernel_data.stacks.stack7;
 22a:	80 e8       	ldi	r24, 0x80	; 128
 22c:	95 e0       	ldi	r25, 0x05	; 5
 22e:	90 93 3d 06 	sts	0x063D, r25	; 0x80063d <__DATA_REGION_ORIGIN__+0x43d>
 232:	80 93 3c 06 	sts	0x063C, r24	; 0x80063c <__DATA_REGION_ORIGIN__+0x43c>
 236:	20 e0       	ldi	r18, 0x00	; 0
 238:	30 e0       	ldi	r19, 0x00	; 0
			// initialize the stack pointer to the stack base
			kernel_data.thread_ctrl_tbl[i].stack_ptr = kernel_data.thread_ctrl_tbl[i].stack_base;
			// initialize the entry point for each thread to null
			kernel_data.thread_ctrl_tbl[i].entry_pnt = (PTHREAD) 0x0000;
			// set the canary in each stack
			*(kernel_data.thread_ctrl_tbl[i].canary_ptr) = CANARY;
 23a:	6a ea       	ldi	r22, 0xAA	; 170
		
		// initialize remaining variables for each thread
		for (uint8_t i = 0; i < MAX_THREADS; ++i)
		{
			// initialize the stack pointer to the stack base
			kernel_data.thread_ctrl_tbl[i].stack_ptr = kernel_data.thread_ctrl_tbl[i].stack_base;
 23c:	c9 01       	movw	r24, r18
 23e:	88 0f       	add	r24, r24
 240:	99 1f       	adc	r25, r25
 242:	88 0f       	add	r24, r24
 244:	99 1f       	adc	r25, r25
 246:	88 0f       	add	r24, r24
 248:	99 1f       	adc	r25, r25
 24a:	80 50       	subi	r24, 0x00	; 0
 24c:	9e 4f       	sbci	r25, 0xFE	; 254
 24e:	fc 01       	movw	r30, r24
 250:	ee 5f       	subi	r30, 0xFE	; 254
 252:	fb 4f       	sbci	r31, 0xFB	; 251
 254:	40 81       	ld	r20, Z
 256:	51 81       	ldd	r21, Z+1	; 0x01
 258:	f9 01       	movw	r30, r18
 25a:	ee 0f       	add	r30, r30
 25c:	ff 1f       	adc	r31, r31
 25e:	ee 0f       	add	r30, r30
 260:	ff 1f       	adc	r31, r31
 262:	ee 0f       	add	r30, r30
 264:	ff 1f       	adc	r31, r31
 266:	e0 50       	subi	r30, 0x00	; 0
 268:	fa 4f       	sbci	r31, 0xFA	; 250
 26a:	51 83       	std	Z+1, r21	; 0x01
 26c:	40 83       	st	Z, r20
			// initialize the entry point for each thread to null
			kernel_data.thread_ctrl_tbl[i].entry_pnt = (PTHREAD) 0x0000;
 26e:	fc 01       	movw	r30, r24
 270:	ea 5f       	subi	r30, 0xFA	; 250
 272:	fb 4f       	sbci	r31, 0xFB	; 251
 274:	11 82       	std	Z+1, r1	; 0x01
 276:	10 82       	st	Z, r1
			// set the canary in each stack
			*(kernel_data.thread_ctrl_tbl[i].canary_ptr) = CANARY;
 278:	32 97       	sbiw	r30, 0x02	; 2
 27a:	01 90       	ld	r0, Z+
 27c:	f0 81       	ld	r31, Z
 27e:	e0 2d       	mov	r30, r0
 280:	60 83       	st	Z, r22
			// clear each delay counter
			kernel_data.delay_ctrs[i] = 0x0000;
 282:	f9 01       	movw	r30, r18
 284:	ee 0f       	add	r30, r30
 286:	ff 1f       	adc	r31, r31
 288:	ee 5b       	subi	r30, 0xBE	; 190
 28a:	f9 4f       	sbci	r31, 0xF9	; 249
 28c:	11 82       	std	Z+1, r1	; 0x01
 28e:	10 82       	st	Z, r1
 290:	2f 5f       	subi	r18, 0xFF	; 255
 292:	3f 4f       	sbci	r19, 0xFF	; 255
		kernel_data.thread_ctrl_tbl[5].canary_ptr = kernel_data.stacks.stack5;
		kernel_data.thread_ctrl_tbl[6].canary_ptr = kernel_data.stacks.stack6;
		kernel_data.thread_ctrl_tbl[7].canary_ptr = kernel_data.stacks.stack7;
		
		// initialize remaining variables for each thread
		for (uint8_t i = 0; i < MAX_THREADS; ++i)
 294:	28 30       	cpi	r18, 0x08	; 8
 296:	31 05       	cpc	r19, r1
 298:	89 f6       	brne	.-94     	; 0x23c <init+0xd0>
			// clear each delay counter
			kernel_data.delay_ctrs[i] = 0x0000;
		}
		
		// set only thread 0 as enabled
		kernel_data.disable_status = 0xfe;
 29a:	8e ef       	ldi	r24, 0xFE	; 254
 29c:	80 93 40 06 	sts	0x0640, r24	; 0x800640 <__DATA_REGION_ORIGIN__+0x440>
		// set all threads to not be delayed
		kernel_data.delay_status = 0x00;
 2a0:	10 92 41 06 	sts	0x0641, r1	; 0x800641 <__DATA_REGION_ORIGIN__+0x441>
		
		// set current thread to thread 0
		kernel_data.cur_thread_id = 0;
 2a4:	10 92 52 06 	sts	0x0652, r1	; 0x800652 <__DATA_REGION_ORIGIN__+0x452>
		kernel_data.cur_thread_mask = 0x01;
 2a8:	81 e0       	ldi	r24, 0x01	; 1
 2aa:	80 93 53 06 	sts	0x0653, r24	; 0x800653 <__DATA_REGION_ORIGIN__+0x453>
		
		// copy the stack to the thread 0 stack
		uint8_t *ptr = (uint8_t *) GCC_STACK_BASE;
		while (ptr > (uint8_t *) SP)
 2ae:	8d b7       	in	r24, 0x3d	; 61
 2b0:	9e b7       	in	r25, 0x3e	; 62
 2b2:	8f 3f       	cpi	r24, 0xFF	; 255
 2b4:	91 42       	sbci	r25, 0x21	; 33
 2b6:	98 f4       	brcc	.+38     	; 0x2de <init+0x172>
 2b8:	ef ef       	ldi	r30, 0xFF	; 255
 2ba:	f1 e2       	ldi	r31, 0x21	; 33
		{
			*(kernel_data.thread_ctrl_tbl[0].stack_ptr--) = *(ptr--);
 2bc:	c0 e0       	ldi	r28, 0x00	; 0
 2be:	d6 e0       	ldi	r29, 0x06	; 6
 2c0:	a8 81       	ld	r26, Y
 2c2:	b9 81       	ldd	r27, Y+1	; 0x01
 2c4:	9d 01       	movw	r18, r26
 2c6:	21 50       	subi	r18, 0x01	; 1
 2c8:	31 09       	sbc	r19, r1
 2ca:	39 83       	std	Y+1, r19	; 0x01
 2cc:	28 83       	st	Y, r18
 2ce:	31 97       	sbiw	r30, 0x01	; 1
 2d0:	21 81       	ldd	r18, Z+1	; 0x01
 2d2:	2c 93       	st	X, r18
		kernel_data.cur_thread_id = 0;
		kernel_data.cur_thread_mask = 0x01;
		
		// copy the stack to the thread 0 stack
		uint8_t *ptr = (uint8_t *) GCC_STACK_BASE;
		while (ptr > (uint8_t *) SP)
 2d4:	2d b7       	in	r18, 0x3d	; 61
 2d6:	3e b7       	in	r19, 0x3e	; 62
 2d8:	2e 17       	cp	r18, r30
 2da:	3f 07       	cpc	r19, r31
 2dc:	88 f3       	brcs	.-30     	; 0x2c0 <init+0x154>
		{
			*(kernel_data.thread_ctrl_tbl[0].stack_ptr--) = *(ptr--);
		}
		SP = (uint16_t) kernel_data.thread_ctrl_tbl[0].stack_ptr;
 2de:	80 91 00 06 	lds	r24, 0x0600	; 0x800600 <__DATA_REGION_ORIGIN__+0x400>
 2e2:	90 91 01 06 	lds	r25, 0x0601	; 0x800601 <__DATA_REGION_ORIGIN__+0x401>
 2e6:	9e bf       	out	0x3e, r25	; 62
 2e8:	8d bf       	out	0x3d, r24	; 61
		
		// initialize system timer
		init_system_timer();
 2ea:	0f df       	rcall	.-482    	; 0x10a <init_system_timer>
    (void)__s;
}

static __inline__ void __iRestore(const  uint8_t *__s)
{
    SREG = *__s;
 2ec:	1f bf       	out	0x3f, r17	; 63
	}
}
 2ee:	df 91       	pop	r29
 2f0:	cf 91       	pop	r28
 2f2:	1f 91       	pop	r17
 2f4:	08 95       	ret

000002f6 <delay>:
 *	Delays the current thread by at least the specified number of milliseconds and yield.
 *
 *	t: minimum delay time in milliseconds
 */
void delay(uint16_t t)
{
 2f6:	ac 01       	movw	r20, r24
	ATOMIC_BLOCK(ATOMIC_RESTORESTATE)
 2f8:	2f b7       	in	r18, 0x3f	; 63
    return 1;
}

static __inline__ uint8_t __iCliRetVal(void)
{
    cli();
 2fa:	f8 94       	cli
	{
		// set current thread's delay bit
		kernel_data.delay_status |= kernel_data.cur_thread_mask;
 2fc:	80 91 53 06 	lds	r24, 0x0653	; 0x800653 <__DATA_REGION_ORIGIN__+0x453>
 300:	e1 e4       	ldi	r30, 0x41	; 65
 302:	f6 e0       	ldi	r31, 0x06	; 6
 304:	90 81       	ld	r25, Z
 306:	98 2b       	or	r25, r24
 308:	90 83       	st	Z, r25
		// set current thread's delay counter
		kernel_data.delay_ctrs[kernel_data.cur_thread_id] = t;
 30a:	e0 91 52 06 	lds	r30, 0x0652	; 0x800652 <__DATA_REGION_ORIGIN__+0x452>
 30e:	f0 e0       	ldi	r31, 0x00	; 0
 310:	ee 0f       	add	r30, r30
 312:	ff 1f       	adc	r31, r31
 314:	ee 5b       	subi	r30, 0xBE	; 190
 316:	f9 4f       	sbci	r31, 0xF9	; 249
 318:	51 83       	std	Z+1, r21	; 0x01
 31a:	40 83       	st	Z, r20
    (void)__s;
}

static __inline__ void __iRestore(const  uint8_t *__s)
{
    SREG = *__s;
 31c:	2f bf       	out	0x3f, r18	; 63
	}
	yield();
 31e:	d1 c0       	rjmp	.+418    	; 0x4c2 <yield>
 320:	08 95       	ret

00000322 <stack_overflow>:
/*
 *	Function that will be entered when a stack overflow is detected.
 */
void stack_overflow()
{
	DDRB |= 0x80;
 322:	27 9a       	sbi	0x04, 7	; 4
	while (1)
	{
		PORTB ^= 0x80;
 324:	85 b1       	in	r24, 0x05	; 5
 326:	80 58       	subi	r24, 0x80	; 128
 328:	85 b9       	out	0x05, r24	; 5
	#else
		//round up by default
		__ticks_dc = (uint32_t)(ceil(fabs(__tmp)));
	#endif

	__builtin_avr_delay_cycles(__ticks_dc);
 32a:	2f ef       	ldi	r18, 0xFF	; 255
 32c:	84 e3       	ldi	r24, 0x34	; 52
 32e:	9c e0       	ldi	r25, 0x0C	; 12
 330:	21 50       	subi	r18, 0x01	; 1
 332:	80 40       	sbci	r24, 0x00	; 0
 334:	90 40       	sbci	r25, 0x00	; 0
 336:	e1 f7       	brne	.-8      	; 0x330 <stack_overflow+0xe>
 338:	00 c0       	rjmp	.+0      	; 0x33a <stack_overflow+0x18>
 33a:	00 00       	nop
 33c:	f3 cf       	rjmp	.-26     	; 0x324 <stack_overflow+0x2>

0000033e <new>:
 *	thread_id:		id of the new thread. Must be between zero and MAX_THREADS
 *	entry_point:	function pointer to the entry point of the thread
 *	enabled:		boolean value if the thread is enabled
 */
void new(uint8_t thread_id, PTHREAD entry_point, bool enabled)
{
 33e:	af 92       	push	r10
 340:	bf 92       	push	r11
 342:	cf 92       	push	r12
 344:	df 92       	push	r13
 346:	ef 92       	push	r14
 348:	ff 92       	push	r15
 34a:	0f 93       	push	r16
 34c:	1f 93       	push	r17
 34e:	cf 93       	push	r28
 350:	df 93       	push	r29
 352:	f8 2e       	mov	r15, r24
 354:	5b 01       	movw	r10, r22
 356:	e4 2e       	mov	r14, r20
	// reset stack pointer to its base
	kernel_data.thread_ctrl_tbl[thread_id].stack_ptr = kernel_data.thread_ctrl_tbl[thread_id].stack_base;
 358:	c8 2e       	mov	r12, r24
 35a:	d1 2c       	mov	r13, r1
 35c:	e6 01       	movw	r28, r12
 35e:	cc 0f       	add	r28, r28
 360:	dd 1f       	adc	r29, r29
 362:	cc 0f       	add	r28, r28
 364:	dd 1f       	adc	r29, r29
 366:	cc 0f       	add	r28, r28
 368:	dd 1f       	adc	r29, r29
 36a:	c0 50       	subi	r28, 0x00	; 0
 36c:	de 4f       	sbci	r29, 0xFE	; 254
 36e:	fe 01       	movw	r30, r28
 370:	ee 5f       	subi	r30, 0xFE	; 254
 372:	fb 4f       	sbci	r31, 0xFB	; 251
 374:	80 81       	ld	r24, Z
 376:	91 81       	ldd	r25, Z+1	; 0x01
 378:	86 01       	movw	r16, r12
 37a:	00 0f       	add	r16, r16
 37c:	11 1f       	adc	r17, r17
 37e:	00 0f       	add	r16, r16
 380:	11 1f       	adc	r17, r17
 382:	00 0f       	add	r16, r16
 384:	11 1f       	adc	r17, r17
 386:	00 50       	subi	r16, 0x00	; 0
 388:	1a 4f       	sbci	r17, 0xFA	; 250
 38a:	f8 01       	movw	r30, r16
 38c:	91 83       	std	Z+1, r25	; 0x01
 38e:	80 83       	st	Z, r24
	// push the entry point to the stack
	push_pthread(thread_id, entry_point);
 390:	8f 2d       	mov	r24, r15
 392:	cf de       	rcall	.-610    	; 0x132 <push_pthread>
	// decrement the stack pointer for the thread's context
	kernel_data.thread_ctrl_tbl[thread_id].stack_ptr -= THREAD_STACK_CONTEXT_SZ;
 394:	f8 01       	movw	r30, r16
 396:	80 81       	ld	r24, Z
 398:	91 81       	ldd	r25, Z+1	; 0x01
 39a:	42 97       	sbiw	r24, 0x12	; 18
 39c:	91 83       	std	Z+1, r25	; 0x01
 39e:	80 83       	st	Z, r24
	// save the entry point to the thread's control data
	kernel_data.thread_ctrl_tbl[thread_id].entry_pnt = entry_point;
 3a0:	ca 5f       	subi	r28, 0xFA	; 250
 3a2:	db 4f       	sbci	r29, 0xFB	; 251
 3a4:	b9 82       	std	Y+1, r11	; 0x01
 3a6:	a8 82       	st	Y, r10
	
	// set or clear thread's disable bit
	if (!enabled)
 3a8:	e1 10       	cpse	r14, r1
 3aa:	0e c0       	rjmp	.+28     	; 0x3c8 <new+0x8a>
	{
		kernel_data.disable_status |= (0x1 << thread_id);
 3ac:	e0 e4       	ldi	r30, 0x40	; 64
 3ae:	f6 e0       	ldi	r31, 0x06	; 6
 3b0:	20 81       	ld	r18, Z
 3b2:	81 e0       	ldi	r24, 0x01	; 1
 3b4:	90 e0       	ldi	r25, 0x00	; 0
 3b6:	0f 2c       	mov	r0, r15
 3b8:	02 c0       	rjmp	.+4      	; 0x3be <new+0x80>
 3ba:	88 0f       	add	r24, r24
 3bc:	99 1f       	adc	r25, r25
 3be:	0a 94       	dec	r0
 3c0:	e2 f7       	brpl	.-8      	; 0x3ba <new+0x7c>
 3c2:	82 2b       	or	r24, r18
 3c4:	80 83       	st	Z, r24
 3c6:	0e c0       	rjmp	.+28     	; 0x3e4 <new+0xa6>
	}
	else
	{
		kernel_data.disable_status &= ~(0x1 << thread_id);
 3c8:	e0 e4       	ldi	r30, 0x40	; 64
 3ca:	f6 e0       	ldi	r31, 0x06	; 6
 3cc:	20 81       	ld	r18, Z
 3ce:	81 e0       	ldi	r24, 0x01	; 1
 3d0:	90 e0       	ldi	r25, 0x00	; 0
 3d2:	0f 2c       	mov	r0, r15
 3d4:	02 c0       	rjmp	.+4      	; 0x3da <new+0x9c>
 3d6:	88 0f       	add	r24, r24
 3d8:	99 1f       	adc	r25, r25
 3da:	0a 94       	dec	r0
 3dc:	e2 f7       	brpl	.-8      	; 0x3d6 <new+0x98>
 3de:	80 95       	com	r24
 3e0:	82 23       	and	r24, r18
 3e2:	80 83       	st	Z, r24
	}
	
	// if the current thread is being recreated, verify stack canary and invoke the scheduler
	if (thread_id == kernel_data.cur_thread_id)
 3e4:	80 91 52 06 	lds	r24, 0x0652	; 0x800652 <__DATA_REGION_ORIGIN__+0x452>
 3e8:	f8 12       	cpse	r15, r24
 3ea:	11 c0       	rjmp	.+34     	; 0x40e <__LOCK_REGION_LENGTH__+0xe>
	{
		if (*(kernel_data.thread_ctrl_tbl[thread_id].canary_ptr) != CANARY) stack_overflow();
 3ec:	f6 01       	movw	r30, r12
 3ee:	ee 0f       	add	r30, r30
 3f0:	ff 1f       	adc	r31, r31
 3f2:	ee 0f       	add	r30, r30
 3f4:	ff 1f       	adc	r31, r31
 3f6:	ee 0f       	add	r30, r30
 3f8:	ff 1f       	adc	r31, r31
 3fa:	ec 5f       	subi	r30, 0xFC	; 252
 3fc:	f9 4f       	sbci	r31, 0xF9	; 249
 3fe:	01 90       	ld	r0, Z+
 400:	f0 81       	ld	r31, Z
 402:	e0 2d       	mov	r30, r0
 404:	80 81       	ld	r24, Z
 406:	8a 3a       	cpi	r24, 0xAA	; 170
 408:	09 f0       	breq	.+2      	; 0x40c <__LOCK_REGION_LENGTH__+0xc>
		schedule();
 40a:	8b df       	rcall	.-234    	; 0x322 <stack_overflow>
 40c:	91 d0       	rcall	.+290    	; 0x530 <schedule>
	}
}
 40e:	df 91       	pop	r29
 410:	cf 91       	pop	r28
 412:	1f 91       	pop	r17
 414:	0f 91       	pop	r16
 416:	ff 90       	pop	r15
 418:	ef 90       	pop	r14
 41a:	df 90       	pop	r13
 41c:	cf 90       	pop	r12
 41e:	bf 90       	pop	r11
 420:	af 90       	pop	r10
 422:	08 95       	ret

00000424 <__vector_13>:

/*
 *	ISR for timer 2. Set to fire every milisecond
 */
ISR(TIMER2_COMPA_vect)
{
 424:	1f 92       	push	r1
 426:	0f 92       	push	r0
 428:	0f b6       	in	r0, 0x3f	; 63
 42a:	0f 92       	push	r0
 42c:	11 24       	eor	r1, r1
 42e:	0b b6       	in	r0, 0x3b	; 59
 430:	0f 92       	push	r0
 432:	2f 93       	push	r18
 434:	3f 93       	push	r19
 436:	4f 93       	push	r20
 438:	5f 93       	push	r21
 43a:	8f 93       	push	r24
 43c:	9f 93       	push	r25
 43e:	af 93       	push	r26
 440:	bf 93       	push	r27
 442:	ef 93       	push	r30
 444:	ff 93       	push	r31
 446:	20 e0       	ldi	r18, 0x00	; 0
 448:	30 e0       	ldi	r19, 0x00	; 0
	// check if each thread is delayed and decrement its counter if so
	uint8_t msk = 0x01;
 44a:	91 e0       	ldi	r25, 0x01	; 1
	for (uint8_t i = 0; i < MAX_THREADS; ++i)
	{
		if (kernel_data.delay_status & msk)
 44c:	a1 e4       	ldi	r26, 0x41	; 65
 44e:	b6 e0       	ldi	r27, 0x06	; 6
 450:	8c 91       	ld	r24, X
 452:	89 23       	and	r24, r25
 454:	91 f0       	breq	.+36     	; 0x47a <__vector_13+0x56>
		{
			if (!(kernel_data.delay_ctrs[i] = kernel_data.delay_ctrs[i] - 1))
 456:	f9 01       	movw	r30, r18
 458:	ee 0f       	add	r30, r30
 45a:	ff 1f       	adc	r31, r31
 45c:	ee 5b       	subi	r30, 0xBE	; 190
 45e:	f9 4f       	sbci	r31, 0xF9	; 249
 460:	40 81       	ld	r20, Z
 462:	51 81       	ldd	r21, Z+1	; 0x01
 464:	41 50       	subi	r20, 0x01	; 1
 466:	51 09       	sbc	r21, r1
 468:	51 83       	std	Z+1, r21	; 0x01
 46a:	40 83       	st	Z, r20
 46c:	45 2b       	or	r20, r21
 46e:	29 f4       	brne	.+10     	; 0x47a <__vector_13+0x56>
			{
				// clear thread's delay bit if counter reached zero
				kernel_data.delay_status &= ~msk;
 470:	8c 91       	ld	r24, X
 472:	49 2f       	mov	r20, r25
 474:	40 95       	com	r20
 476:	84 23       	and	r24, r20
 478:	8c 93       	st	X, r24
			}
		}
		msk <<= 1;
 47a:	99 0f       	add	r25, r25
 47c:	2f 5f       	subi	r18, 0xFF	; 255
 47e:	3f 4f       	sbci	r19, 0xFF	; 255
 */
ISR(TIMER2_COMPA_vect)
{
	// check if each thread is delayed and decrement its counter if so
	uint8_t msk = 0x01;
	for (uint8_t i = 0; i < MAX_THREADS; ++i)
 480:	28 30       	cpi	r18, 0x08	; 8
 482:	31 05       	cpc	r19, r1
 484:	29 f7       	brne	.-54     	; 0x450 <__vector_13+0x2c>
		}
		msk <<= 1;
	}
	
	// increment system time
	++kernel_data.system_time_millis;
 486:	e4 e5       	ldi	r30, 0x54	; 84
 488:	f6 e0       	ldi	r31, 0x06	; 6
 48a:	80 81       	ld	r24, Z
 48c:	91 81       	ldd	r25, Z+1	; 0x01
 48e:	a2 81       	ldd	r26, Z+2	; 0x02
 490:	b3 81       	ldd	r27, Z+3	; 0x03
 492:	01 96       	adiw	r24, 0x01	; 1
 494:	a1 1d       	adc	r26, r1
 496:	b1 1d       	adc	r27, r1
 498:	80 83       	st	Z, r24
 49a:	91 83       	std	Z+1, r25	; 0x01
 49c:	a2 83       	std	Z+2, r26	; 0x02
 49e:	b3 83       	std	Z+3, r27	; 0x03
}
 4a0:	ff 91       	pop	r31
 4a2:	ef 91       	pop	r30
 4a4:	bf 91       	pop	r27
 4a6:	af 91       	pop	r26
 4a8:	9f 91       	pop	r25
 4aa:	8f 91       	pop	r24
 4ac:	5f 91       	pop	r21
 4ae:	4f 91       	pop	r20
 4b0:	3f 91       	pop	r19
 4b2:	2f 91       	pop	r18
 4b4:	0f 90       	pop	r0
 4b6:	0b be       	out	0x3b, r0	; 59
 4b8:	0f 90       	pop	r0
 4ba:	0f be       	out	0x3f, r0	; 63
 4bc:	0f 90       	pop	r0
 4be:	1f 90       	pop	r1
 4c0:	18 95       	reti

000004c2 <yield>:
    return 1;
}

static __inline__ uint8_t __iCliRetVal(void)
{
    cli();
 4c2:	f8 94       	cli

void yield()
{
	ATOMIC_BLOCK(ATOMIC_FORCEON)
	{
		asm volatile ("push r2\n\
 4c4:	2f 92       	push	r2
 4c6:	3f 92       	push	r3
 4c8:	4f 92       	push	r4
 4ca:	5f 92       	push	r5
 4cc:	6f 92       	push	r6
 4ce:	7f 92       	push	r7
 4d0:	8f 92       	push	r8
 4d2:	9f 92       	push	r9
 4d4:	af 92       	push	r10
 4d6:	bf 92       	push	r11
 4d8:	cf 92       	push	r12
 4da:	df 92       	push	r13
 4dc:	ef 92       	push	r14
 4de:	ff 92       	push	r15
 4e0:	0f 93       	push	r16
 4e2:	1f 93       	push	r17
 4e4:	cf 93       	push	r28
 4e6:	df 93       	push	r29
					   push r16\n\
					   push r17\n\
					   push r28\n\
					   push r29");
		
		if (*kernel_data.thread_ctrl_tbl[kernel_data.cur_thread_id].canary_ptr != CANARY)
 4e8:	e0 91 52 06 	lds	r30, 0x0652	; 0x800652 <__DATA_REGION_ORIGIN__+0x452>
 4ec:	f0 e0       	ldi	r31, 0x00	; 0
 4ee:	ee 0f       	add	r30, r30
 4f0:	ff 1f       	adc	r31, r31
 4f2:	ee 0f       	add	r30, r30
 4f4:	ff 1f       	adc	r31, r31
 4f6:	ee 0f       	add	r30, r30
 4f8:	ff 1f       	adc	r31, r31
 4fa:	ec 5f       	subi	r30, 0xFC	; 252
 4fc:	f9 4f       	sbci	r31, 0xF9	; 249
 4fe:	01 90       	ld	r0, Z+
 500:	f0 81       	ld	r31, Z
 502:	e0 2d       	mov	r30, r0
 504:	80 81       	ld	r24, Z
 506:	8a 3a       	cpi	r24, 0xAA	; 170
 508:	09 f0       	breq	.+2      	; 0x50c <yield+0x4a>
		{
			stack_overflow();
 50a:	0b df       	rcall	.-490    	; 0x322 <stack_overflow>
		}
		
		kernel_data.thread_ctrl_tbl[kernel_data.cur_thread_id].stack_ptr = (uint8_t *) SP;
 50c:	e0 91 52 06 	lds	r30, 0x0652	; 0x800652 <__DATA_REGION_ORIGIN__+0x452>
 510:	f0 e0       	ldi	r31, 0x00	; 0
 512:	8d b7       	in	r24, 0x3d	; 61
 514:	9e b7       	in	r25, 0x3e	; 62
 516:	ee 0f       	add	r30, r30
 518:	ff 1f       	adc	r31, r31
 51a:	ee 0f       	add	r30, r30
 51c:	ff 1f       	adc	r31, r31
 51e:	ee 0f       	add	r30, r30
 520:	ff 1f       	adc	r31, r31
 522:	e0 50       	subi	r30, 0x00	; 0
 524:	fa 4f       	sbci	r31, 0xFA	; 250
 526:	91 83       	std	Z+1, r25	; 0x01
		
		asm volatile ("jmp schedule");
 528:	80 83       	st	Z, r24
 52a:	02 c0       	rjmp	.+4      	; 0x530 <schedule>
    return 1;
}

static __inline__ void __iSeiParam(const uint8_t *__s)
{
    sei();
 52c:	78 94       	sei
    __asm__ volatile ("" ::: "memory");
 52e:	08 95       	ret

00000530 <schedule>:
    return 1;
}

static __inline__ uint8_t __iCliRetVal(void)
{
    cli();
 530:	f8 94       	cli
void schedule()
{
	ATOMIC_BLOCK(ATOMIC_FORCEON)
	{
		uint8_t ready_status = 0x00;
		while (!(ready_status = kernel_data.disable_status | kernel_data.disable_status))
 532:	e0 e4       	ldi	r30, 0x40	; 64
 534:	f6 e0       	ldi	r31, 0x06	; 6
 536:	90 81       	ld	r25, Z
 538:	80 81       	ld	r24, Z
 53a:	89 2b       	or	r24, r25
 53c:	e1 f3       	breq	.-8      	; 0x536 <schedule+0x6>
		{
			sleep_mode();
		}
		uint8_t tid = kernel_data.cur_thread_id;
 53e:	e0 91 52 06 	lds	r30, 0x0652	; 0x800652 <__DATA_REGION_ORIGIN__+0x452>
		uint8_t tmsk = kernel_data.cur_thread_mask;
 542:	90 91 53 06 	lds	r25, 0x0653	; 0x800653 <__DATA_REGION_ORIGIN__+0x453>
		
		do
		{
			tid = (tid + 1) & 0x07;
 546:	ef 5f       	subi	r30, 0xFF	; 255
 548:	e7 70       	andi	r30, 0x07	; 7
			asm volatile ("lsl %1\n"
 54a:	99 0f       	add	r25, r25
 54c:	91 1d       	adc	r25, r1
						  "adc %1, r1"
						  : "=r" (tmsk)
						  : "r" (tmsk));
		} while (!(ready_status & tmsk));
 54e:	28 2f       	mov	r18, r24
 550:	29 23       	and	r18, r25
 552:	c9 f3       	breq	.-14     	; 0x546 <schedule+0x16>
		
		kernel_data.cur_thread_id = tid;
 554:	e0 93 52 06 	sts	0x0652, r30	; 0x800652 <__DATA_REGION_ORIGIN__+0x452>
		kernel_data.cur_thread_mask = tmsk;
 558:	90 93 53 06 	sts	0x0653, r25	; 0x800653 <__DATA_REGION_ORIGIN__+0x453>
		
		SP = (uint16_t) kernel_data.thread_ctrl_tbl[tid].stack_ptr;
 55c:	f0 e0       	ldi	r31, 0x00	; 0
 55e:	ee 0f       	add	r30, r30
 560:	ff 1f       	adc	r31, r31
 562:	ee 0f       	add	r30, r30
 564:	ff 1f       	adc	r31, r31
 566:	ee 0f       	add	r30, r30
 568:	ff 1f       	adc	r31, r31
 56a:	e0 50       	subi	r30, 0x00	; 0
 56c:	fa 4f       	sbci	r31, 0xFA	; 250
 56e:	80 81       	ld	r24, Z
 570:	91 81       	ldd	r25, Z+1	; 0x01
 572:	9e bf       	out	0x3e, r25	; 62
 574:	8d bf       	out	0x3d, r24	; 61
		
		asm volatile ("pop r29\n\
 576:	df 91       	pop	r29
 578:	cf 91       	pop	r28
 57a:	1f 91       	pop	r17
 57c:	0f 91       	pop	r16
 57e:	ff 90       	pop	r15
 580:	ef 90       	pop	r14
 582:	df 90       	pop	r13
 584:	cf 90       	pop	r12
 586:	bf 90       	pop	r11
 588:	af 90       	pop	r10
 58a:	9f 90       	pop	r9
 58c:	8f 90       	pop	r8
 58e:	7f 90       	pop	r7
 590:	6f 90       	pop	r6
 592:	5f 90       	pop	r5
 594:	4f 90       	pop	r4
 596:	3f 90       	pop	r3
 598:	2f 90       	pop	r2
    return 1;
}

static __inline__ void __iSeiParam(const uint8_t *__s)
{
    sei();
 59a:	78 94       	sei
    __asm__ volatile ("" ::: "memory");
 59c:	08 95       	ret

0000059e <f0>:

void f0()
{
	while(1)
	{
		delay(3);
 59e:	83 e0       	ldi	r24, 0x03	; 3
 5a0:	90 e0       	ldi	r25, 0x00	; 0
 5a2:	a9 de       	rcall	.-686    	; 0x2f6 <delay>
 5a4:	fc cf       	rjmp	.-8      	; 0x59e <f0>

000005a6 <f1>:

void f1()
{
	while(1)
	{
		delay(5);
 5a6:	85 e0       	ldi	r24, 0x05	; 5
 5a8:	90 e0       	ldi	r25, 0x00	; 0
 5aa:	a5 de       	rcall	.-694    	; 0x2f6 <delay>
 5ac:	fc cf       	rjmp	.-8      	; 0x5a6 <f1>

000005ae <f2>:

void f2()
{
	while(1)
	{
		delay(7);
 5ae:	87 e0       	ldi	r24, 0x07	; 7
 5b0:	90 e0       	ldi	r25, 0x00	; 0
 5b2:	a1 de       	rcall	.-702    	; 0x2f6 <delay>
 5b4:	fc cf       	rjmp	.-8      	; 0x5ae <f2>

000005b6 <main>:
	}
}

int main(void)
{
    init();
 5b6:	da dd       	rcall	.-1100   	; 0x16c <init>
	
	new(1, f1, true);
 5b8:	41 e0       	ldi	r20, 0x01	; 1
 5ba:	63 ed       	ldi	r22, 0xD3	; 211
 5bc:	72 e0       	ldi	r23, 0x02	; 2
 5be:	81 e0       	ldi	r24, 0x01	; 1
 5c0:	be de       	rcall	.-644    	; 0x33e <new>
	new(2, f2, true);
 5c2:	41 e0       	ldi	r20, 0x01	; 1
 5c4:	67 ed       	ldi	r22, 0xD7	; 215
 5c6:	72 e0       	ldi	r23, 0x02	; 2
 5c8:	82 e0       	ldi	r24, 0x02	; 2
 5ca:	b9 de       	rcall	.-654    	; 0x33e <new>
	new(0, f0, true);
 5cc:	41 e0       	ldi	r20, 0x01	; 1
 5ce:	6f ec       	ldi	r22, 0xCF	; 207
 5d0:	72 e0       	ldi	r23, 0x02	; 2
 5d2:	80 e0       	ldi	r24, 0x00	; 0
	
	yield();
 5d4:	b4 de       	rcall	.-664    	; 0x33e <new>
 5d6:	75 df       	rcall	.-278    	; 0x4c2 <yield>
 5d8:	ff cf       	rjmp	.-2      	; 0x5d8 <main+0x22>

000005da <_exit>:
 5da:	f8 94       	cli

000005dc <__stop_program>:
 5dc:	ff cf       	rjmp	.-2      	; 0x5dc <__stop_program>
